{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Fundamental Risk Return Portfolio"
      ],
      "metadata": {
        "id": "-6C2aYWNb5Hx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CHo69XNBbwij"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stockFileName = '/content/DJIA_Apr112014_Apr112019.csv'\n",
        "rows = 1259\n",
        "columns = 29"
      ],
      "metadata": {
        "id": "ZjGy_SUH_bg1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(stockFileName, nrows=rows)"
      ],
      "metadata": {
        "id": "7UJtkK_m_xjz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assetLabels = df.columns[1:columns+1].tolist()\n",
        "print(assetLabels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXvWcMAb_6xM",
        "outputId": "bd520aa8-c080-4b55-9ae2-aee0f22a3a0f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'CVX', 'DIS', 'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'KO', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PFE', 'PG', 'TRV', 'UNH', 'UTX', 'V', 'VZ', 'WBA', 'WMT', 'XOM']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stockPrice = df.iloc[0:, 1:]\n",
        "print(stockPrice.shape)\n",
        "print(stockPrice)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4uZS7OEAGRS",
        "outputId": "48fbd790-7bcb-4d02-90c5-1575f0d39c6b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1259, 29)\n",
            "            AAPL         AXP          BA         CAT       CSCO         CVX  \\\n",
            "0      74.230003   84.540001  122.070000  101.449997  22.459999  117.029999   \n",
            "1      74.525711   85.500000  123.250000  102.779999  22.850000  118.699997   \n",
            "2      73.994286   86.040001  124.269997  102.500000  22.889999  120.300003   \n",
            "3      74.144287   87.400002  126.040001  102.930000  23.030001  121.830002   \n",
            "4      74.991432   86.220001  127.919998  102.830002  23.209999  123.680000   \n",
            "...          ...         ...         ...         ...        ...         ...   \n",
            "1254  197.000000  110.959999  391.929993  140.360001  55.209999  126.419998   \n",
            "1255  200.100006  110.699997  374.519989  139.820007  55.490002  126.680000   \n",
            "1256  199.500000  109.849998  369.040009  136.350006  55.180000  125.540001   \n",
            "1257  200.619995  110.160004  364.940002  137.529999  55.820000  125.489998   \n",
            "1258  198.949997  109.849998  370.160004  138.869995  55.599998  125.989998   \n",
            "\n",
            "             DIS          GS          HD         IBM  ...        PFE  \\\n",
            "0      77.010002  152.720001   75.699997  195.190002  ...  29.860001   \n",
            "1      77.620003  154.740005   75.970001  197.770004  ...  29.870001   \n",
            "2      77.660004  154.919998   75.889999  197.020004  ...  29.889999   \n",
            "3      78.949997  157.220001   76.580002  196.399994  ...  30.090000   \n",
            "4      79.989998  157.440002   77.089996  190.009995  ...  30.250000   \n",
            "...          ...         ...         ...         ...  ...        ...   \n",
            "1254  115.000000  202.380005  202.059998  143.279999  ...  42.990002   \n",
            "1255  114.959999  202.539993  203.550003  143.389999  ...  43.139999   \n",
            "1256  116.860001  200.619995  200.899994  142.110001  ...  42.840000   \n",
            "1257  117.160004  202.979996  199.429993  143.020004  ...  42.730000   \n",
            "1258  116.599998  202.830002  201.479996  143.779999  ...  42.270000   \n",
            "\n",
            "              PG         TRV         UNH         UTX           V         VZ  \\\n",
            "0      80.760002   85.300003   78.949997  113.930000   49.157501  47.070000   \n",
            "1      80.809998   85.500000   79.180000  114.940002   50.252499  47.270000   \n",
            "2      80.839996   85.889999   79.510002  115.839996   51.012501  46.919998   \n",
            "3      81.650002   86.779999   78.190002  118.070000   52.340000  47.099998   \n",
            "4      81.760002   86.680000   75.779999  118.570000   51.987499  47.599998   \n",
            "...          ...         ...         ...         ...         ...        ...   \n",
            "1254  103.650002  136.399994  248.779999  133.720001  157.649994  59.090000   \n",
            "1255  104.970001  135.880005  248.750000  133.559998  157.750000  59.130001   \n",
            "1256  104.660004  135.190002  248.789993  132.250000  157.490005  58.400002   \n",
            "1257  104.650002  135.460007  246.029999  131.660004  158.559998  58.610001   \n",
            "1258  104.750000  136.279999  235.419998  132.820007  157.860001  58.560001   \n",
            "\n",
            "            WBA         WMT         XOM  \n",
            "0     64.260002   76.500000   96.720001  \n",
            "1     65.669998   77.379997   97.860001  \n",
            "2     66.010002   76.879997   98.680000  \n",
            "3     66.160004   77.220001   99.940002  \n",
            "4     66.750000   77.660004  100.419998  \n",
            "...         ...         ...         ...  \n",
            "1254  54.689999   98.830002   82.489998  \n",
            "1255  55.060001   99.230003   83.000000  \n",
            "1256  54.500000   98.690002   81.930000  \n",
            "1257  54.509998   99.599998   81.559998  \n",
            "1258  53.439999  100.800003   81.949997  \n",
            "\n",
            "[1259 rows x 29 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def StockReturnsComputing(StockPrice, Rows, Columns):\n",
        "\n",
        "  StockReturn = np.zeros([Rows-1, Columns])\n",
        "  for j in range(Columns):\n",
        "    for i in range(Rows-1):\n",
        "      StockReturn[i,j] = ((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])*100\n",
        "\n",
        "  return StockReturn"
      ],
      "metadata": {
        "id": "O1Y5yokgGLvO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stockPriceArray = np.asarray(stockPrice)\n",
        "[Rows, Cols] = stockPriceArray.shape\n",
        "stockReturns = StockReturnsComputing(stockPriceArray, Rows, Cols)\n",
        "print('Daily returns of selective Dow 30 stocks \\n', stockReturns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKP_aegf1_Lc",
        "outputId": "845fe850-7637-4939-e743-a887f6c24c8e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daily returns of selective Dow 30 stocks \n",
            " [[ 0.39836722  1.13555594  0.96665847 ...  2.19420472  1.15032288\n",
            "   1.17866004]\n",
            " [-0.71307606  0.63158012  0.82758377 ...  0.51774632 -0.64616182\n",
            "   0.83793071]\n",
            " [ 0.20271971  1.5806613   1.42432127 ...  0.22724132  0.44225288\n",
            "   1.27685651]\n",
            " ...\n",
            " [-0.29985306 -0.76784013 -1.46320094 ... -1.01707408 -0.54419126\n",
            "  -1.28915663]\n",
            " [ 0.561401    0.28220847 -1.11099255 ...  0.01834495  0.92207517\n",
            "  -0.45160747]\n",
            " [-0.83241852 -0.2814143   1.43037266 ... -1.96294082  1.20482432\n",
            "   0.47817436]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute mean returns and variance covariance matrix of returns\n",
        "meanReturns = np.mean(stockReturns, axis = 0)\n",
        "print('Mean returns of Dow Stocks:\\n',  meanReturns)\n",
        "covReturns = np.cov(stockReturns, rowvar=False)\n",
        "print('Variance-covariance matrix of returns of Dow Stocks:\\n')\n",
        "print(covReturns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaGFo6ianAI-",
        "outputId": "bf60b8d3-0701-4141-ff48-827629e5f3f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean returns of Dow Stocks:\n",
            " [ 0.09027598  0.02910022  0.09966449  0.0386567   0.0809993   0.01551509\n",
            "  0.03975381  0.03313877  0.08479014 -0.01611022  0.07274221  0.03154811\n",
            "  0.06041058  0.01915697  0.05653419  0.04422144  0.03579986  0.09974359\n",
            "  0.08008644  0.03375828  0.02514231  0.04254659  0.09548076  0.01871582\n",
            "  0.10128134  0.02314321 -0.00168528  0.02946248 -0.0061016 ]\n",
            "Variance-covariance matrix of returns of Dow Stocks:\n",
            "\n",
            "[[2.37512857 0.67159954 0.96196299 1.04226142 0.99890235 0.66413311\n",
            "  0.68002487 0.9540385  0.72630968 0.70945859 1.07333017 0.48572094\n",
            "  0.8251006  0.30601011 0.45823283 0.73218    0.53433977 1.22660419\n",
            "  0.77524223 0.5444771  0.41917661 0.50943202 0.77433417 0.69274799\n",
            "  1.0086701  0.29354661 0.69735896 0.44587945 0.63272823]\n",
            " [0.67159954 1.64817768 0.80008198 0.9502813  0.70010508 0.63080612\n",
            "  0.56872139 1.06463549 0.65826615 0.66251941 0.73789772 0.47196466\n",
            "  1.00101545 0.30743029 0.35037656 0.65268493 0.55568077 0.7945144\n",
            "  0.68112631 0.54156063 0.34473927 0.53506318 0.71830933 0.67723734\n",
            "  0.84700893 0.34247718 0.66688086 0.37953128 0.52158702]\n",
            " [0.96196299 0.80008198 2.28788869 1.31010124 0.88951117 0.81235903\n",
            "  0.71613388 1.06553088 0.7474291  0.77691868 0.96595019 0.56720978\n",
            "  0.97737004 0.38099252 0.47170257 0.87223471 0.57833707 0.92506778\n",
            "  0.8218734  0.53242063 0.41390469 0.62206326 0.74452648 0.93342475\n",
            "  0.92483951 0.42031728 0.67937008 0.50859443 0.72979658]\n",
            " [1.04226142 0.9502813  1.31010124 2.73293774 1.04070962 1.23579738\n",
            "  0.68846207 1.32135157 0.79609702 0.88512353 1.15246617 0.53207219\n",
            "  1.16862013 0.3575928  0.45532119 1.06821468 0.61626811 1.10384461\n",
            "  0.78896131 0.60979315 0.39121348 0.67869145 0.72009107 0.98562753\n",
            "  0.96349618 0.400679   0.68112899 0.43156621 1.05224209]\n",
            " [0.99890235 0.70010508 0.88951117 1.04070962 1.78902556 0.77315447\n",
            "  0.71301493 0.92736842 0.72425245 0.81719807 1.15660938 0.58309596\n",
            "  0.90853687 0.36218917 0.47658137 0.80528362 0.64732853 1.14200595\n",
            "  0.78507677 0.62237188 0.44128741 0.58736908 0.65635776 0.73868178\n",
            "  0.9396166  0.45371174 0.70654156 0.56006952 0.70953946]\n",
            " [0.66413311 0.63080612 0.81235903 1.23579738 0.77315447 1.932096\n",
            "  0.57422635 0.92783679 0.59651661 0.67870537 0.80956635 0.50655966\n",
            "  0.92523497 0.38139009 0.43457364 0.6903186  0.58157564 0.80664559\n",
            "  0.54177056 0.50672642 0.42583641 0.5708276  0.58621616 0.62326693\n",
            "  0.70656875 0.47564428 0.57628063 0.36149511 1.28443402]\n",
            " [0.68002487 0.56872139 0.71613388 0.68846207 0.71301493 0.57422635\n",
            "  1.35048191 0.77289139 0.58578463 0.57403111 0.72263063 0.39298643\n",
            "  0.71657743 0.3017284  0.36846253 0.55643828 0.46561062 0.67219088\n",
            "  0.66536599 0.47665498 0.36173875 0.49229329 0.55685825 0.5388492\n",
            "  0.67278109 0.41338199 0.63107721 0.40505355 0.56518704]\n",
            " [0.9540385  1.06463549 1.06553088 1.32135157 0.92736842 0.92783679\n",
            "  0.77289139 2.1138036  0.79525    0.80262739 1.00421204 0.5480571\n",
            "  1.55356454 0.30302496 0.46719648 0.84032034 0.70486405 1.02298914\n",
            "  0.7633673  0.62992167 0.3658698  0.77258711 0.81982371 0.82657363\n",
            "  1.00074604 0.40619105 0.81891634 0.41893615 0.80896708]\n",
            " [0.72630968 0.65826615 0.7474291  0.79609702 0.72425245 0.59651661\n",
            "  0.58578463 0.79525    1.3897185  0.61904803 0.74277819 0.46273836\n",
            "  0.75294425 0.34308617 0.47212001 0.64962548 0.4866731  0.78442675\n",
            "  0.81991843 0.5270469  0.38869254 0.54309905 0.65908572 0.59748122\n",
            "  0.79335092 0.40774674 0.6886112  0.55004085 0.51060107]\n",
            " [0.70945859 0.66251941 0.77691868 0.88512353 0.81719807 0.67870537\n",
            "  0.57403111 0.80262739 0.61904803 1.63226569 0.84349145 0.46439182\n",
            "  0.76717143 0.37157516 0.39096364 0.65073111 0.57614062 0.87286369\n",
            "  0.59226376 0.51273082 0.42835501 0.5309683  0.56366909 0.72098388\n",
            "  0.75236424 0.4445684  0.53380786 0.42994184 0.62132567]\n",
            " [1.07333017 0.73789772 0.96595019 1.15246617 1.15660938 0.80956635\n",
            "  0.72263063 1.00421204 0.74277819 0.84349145 2.5195914  0.55940497\n",
            "  0.92434812 0.39589367 0.44534822 0.86494966 0.64920211 1.33841005\n",
            "  0.74573698 0.64343442 0.44494161 0.61596263 0.71733199 0.76577121\n",
            "  0.94849863 0.45110502 0.7420937  0.45376612 0.74855107]\n",
            " [0.48572094 0.47196466 0.56720978 0.53207219 0.58309596 0.50655966\n",
            "  0.39298643 0.5480571  0.46273836 0.46439182 0.55940497 1.00141421\n",
            "  0.54407322 0.37413977 0.42465458 0.59482171 0.64932007 0.58741227\n",
            "  0.47386734 0.59794565 0.42766657 0.4613535  0.55089357 0.47737998\n",
            "  0.54672332 0.42971094 0.57914349 0.40038253 0.5033388 ]\n",
            " [0.8251006  1.00101545 0.97737004 1.16862013 0.90853687 0.92523497\n",
            "  0.71657743 1.55356454 0.75294425 0.76717143 0.92434812 0.54407322\n",
            "  1.70226421 0.32373671 0.4832029  0.7922617  0.67528448 0.92505458\n",
            "  0.72935902 0.63717426 0.36924885 0.78505295 0.76115789 0.7564726\n",
            "  0.88179126 0.42799605 0.71716322 0.429858   0.79929981]\n",
            " [0.30601011 0.30743029 0.38099252 0.3575928  0.36218917 0.38139009\n",
            "  0.3017284  0.30302496 0.34308617 0.37157516 0.39589367 0.37413977\n",
            "  0.32373671 0.80620631 0.36013003 0.40569467 0.3838862  0.43059045\n",
            "  0.36992108 0.29980306 0.47161157 0.41169434 0.30970825 0.34156821\n",
            "  0.3566923  0.3967689  0.35538981 0.34610452 0.34374569]\n",
            " [0.45823283 0.35037656 0.47170257 0.45532119 0.47658137 0.43457364\n",
            "  0.36846253 0.46719648 0.47212001 0.39096364 0.44534822 0.42465458\n",
            "  0.4832029  0.36013003 1.08645862 0.42034437 0.40168401 0.57180894\n",
            "  0.45589715 0.34922409 0.36113169 0.42965168 0.43029041 0.36170601\n",
            "  0.49314053 0.35738508 0.43294896 0.37945512 0.38461827]\n",
            " [0.73218    0.65268493 0.87223471 1.06821468 0.80528362 0.6903186\n",
            "  0.55643828 0.84032034 0.64962548 0.65073111 0.86494966 0.59482171\n",
            "  0.7922617  0.40569467 0.42034437 1.23949227 0.58756374 0.82671503\n",
            "  0.64157778 0.55172153 0.41912491 0.62094738 0.62246677 0.74508991\n",
            "  0.74666898 0.40804632 0.62544734 0.42671961 0.64933174]\n",
            " [0.53433977 0.55568077 0.57833707 0.61626811 0.64732853 0.58157564\n",
            "  0.46561062 0.70486405 0.4866731  0.57614062 0.64920211 0.64932007\n",
            "  0.67528448 0.3838862  0.40168401 0.58756374 1.5043898  0.63257047\n",
            "  0.51638898 0.79082276 0.41487843 0.48436208 0.61451124 0.47522323\n",
            "  0.6132868  0.48144284 0.64004378 0.45948971 0.56611981]\n",
            " [1.22660419 0.7945144  0.92506778 1.10384461 1.14200595 0.80664559\n",
            "  0.67219088 1.02298914 0.78442675 0.87286369 1.33841005 0.58741227\n",
            "  0.92505458 0.43059045 0.57180894 0.82671503 0.63257047 2.12289303\n",
            "  0.84515648 0.65477087 0.4918338  0.62489805 0.81476537 0.76295069\n",
            "  1.17480747 0.45864529 0.83234273 0.4839239  0.66480043]\n",
            " [0.77524223 0.68112631 0.8218734  0.78896131 0.78507677 0.54177056\n",
            "  0.66536599 0.7633673  0.81991843 0.59226376 0.74573698 0.47386734\n",
            "  0.72935902 0.36992108 0.45589715 0.64157778 0.51638898 0.84515648\n",
            "  2.2110946  0.49981829 0.3854958  0.51341632 0.66458782 0.59963521\n",
            "  0.83936583 0.36567803 0.68944143 0.51048011 0.49289368]\n",
            " [0.5444771  0.54156063 0.53242063 0.60979315 0.62237188 0.50672642\n",
            "  0.47665498 0.62992167 0.5270469  0.51273082 0.64343442 0.59794565\n",
            "  0.63717426 0.29980306 0.34922409 0.55172153 0.79082276 0.65477087\n",
            "  0.49981829 1.22879713 0.36723356 0.4610153  0.6697631  0.50914121\n",
            "  0.60315567 0.38318442 0.64267657 0.42400373 0.50641961]\n",
            " [0.41917661 0.34473927 0.41390469 0.39121348 0.44128741 0.42583641\n",
            "  0.36173875 0.3658698  0.38869254 0.42835501 0.44494161 0.42766657\n",
            "  0.36924885 0.47161157 0.36113169 0.41912491 0.41487843 0.4918338\n",
            "  0.3854958  0.36723356 0.89602256 0.39177289 0.36013677 0.37091905\n",
            "  0.41507424 0.41455209 0.43448343 0.41645975 0.40484976]\n",
            " [0.50943202 0.53506318 0.62206326 0.67869145 0.58736908 0.5708276\n",
            "  0.49229329 0.77258711 0.54309905 0.5309683  0.61596263 0.4613535\n",
            "  0.78505295 0.41169434 0.42965168 0.62094738 0.48436208 0.62489805\n",
            "  0.51341632 0.4610153  0.39177289 1.05609328 0.57490249 0.5598936\n",
            "  0.5672914  0.42760787 0.55136283 0.38799285 0.51716774]\n",
            " [0.77433417 0.71830933 0.74452648 0.72009107 0.65635776 0.58621616\n",
            "  0.55685825 0.81982371 0.65908572 0.56366909 0.71733199 0.55089357\n",
            "  0.76115789 0.30970825 0.43029041 0.62246677 0.61451124 0.81476537\n",
            "  0.66458782 0.6697631  0.36013677 0.57490249 1.72193806 0.59735461\n",
            "  0.74636076 0.35659433 0.78012842 0.48215088 0.53046732]\n",
            " [0.69274799 0.67723734 0.93342475 0.98562753 0.73868178 0.62326693\n",
            "  0.5388492  0.82657363 0.59748122 0.72098388 0.76577121 0.47737998\n",
            "  0.7564726  0.34156821 0.36170601 0.74508991 0.47522323 0.76295069\n",
            "  0.59963521 0.50914121 0.37091905 0.5598936  0.59735461 1.30072769\n",
            "  0.73576514 0.37269622 0.62108866 0.44736971 0.57223138]\n",
            " [1.0086701  0.84700893 0.92483951 0.96349618 0.9396166  0.70656875\n",
            "  0.67278109 1.00074604 0.79335092 0.75236424 0.94849863 0.54672332\n",
            "  0.88179126 0.3566923  0.49314053 0.74666898 0.6132868  1.17480747\n",
            "  0.83936583 0.60315567 0.41507424 0.5672914  0.74636076 0.73576514\n",
            "  1.70685388 0.33726478 0.72017945 0.42402111 0.62643838]\n",
            " [0.29354661 0.34247718 0.42031728 0.400679   0.45371174 0.47564428\n",
            "  0.41338199 0.40619105 0.40774674 0.4445684  0.45110502 0.42971094\n",
            "  0.42799605 0.3967689  0.35738508 0.40804632 0.48144284 0.45864529\n",
            "  0.36567803 0.38318442 0.41455209 0.42760787 0.35659433 0.37269622\n",
            "  0.33726478 1.15714096 0.48910367 0.41384225 0.41153949]\n",
            " [0.69735896 0.66688086 0.67937008 0.68112899 0.70654156 0.57628063\n",
            "  0.63107721 0.81891634 0.6886112  0.53380786 0.7420937  0.57914349\n",
            "  0.71716322 0.35538981 0.43294896 0.62544734 0.64004378 0.83234273\n",
            "  0.68944143 0.64267657 0.43448343 0.55136283 0.78012842 0.62108866\n",
            "  0.72017945 0.48910367 2.55412679 0.62471282 0.50655322]\n",
            " [0.44587945 0.37953128 0.50859443 0.43156621 0.56006952 0.36149511\n",
            "  0.40505355 0.41893615 0.55004085 0.42994184 0.45376612 0.40038253\n",
            "  0.429858   0.34610452 0.37945512 0.42671961 0.45948971 0.4839239\n",
            "  0.51048011 0.42400373 0.41645975 0.38799285 0.48215088 0.44736971\n",
            "  0.42402111 0.41384225 0.62471282 1.50880951 0.36486707]\n",
            " [0.63272823 0.52158702 0.72979658 1.05224209 0.70953946 1.28443402\n",
            "  0.56518704 0.80896708 0.51060107 0.62132567 0.74855107 0.5033388\n",
            "  0.79929981 0.34374569 0.38461827 0.64933174 0.56611981 0.66480043\n",
            "  0.49289368 0.50641961 0.40484976 0.51716774 0.53046732 0.57223138\n",
            "  0.62643838 0.41153949 0.50655322 0.36486707 1.41401567]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stockFileName = '/content/DJIAkpf1Apr2016to20193YBeta.csv'\n",
        "marketFileName = '/content/DJIAMarketDataApr2016to20193YBeta.csv'\n",
        "stockRows = 756\n",
        "stockColumns = 15\n",
        "marketRows = 756\n",
        "marketColumns = 7\n",
        "\n",
        "dfStock = pd.read_csv(stockFileName,  nrows= stockRows)\n",
        "dfMarket = pd.read_csv(marketFileName, nrows = marketRows)\n",
        "\n",
        "assetLabels = dfStock.columns[1:stockColumns+1].tolist()\n",
        "print('Portfolio stocks\\n', assetLabels)\n",
        "\n",
        "stockData = dfStock.iloc[0:, 1:]\n",
        "marketData = dfMarket.iloc[0:, [4]]\n",
        "\n",
        "arrayStockData = np.asarray(stockData)\n",
        "[sRows, sCols]=arrayStockData.shape\n",
        "stockReturns = StockReturnsComputing(arrayStockData, sRows, sCols)\n",
        "\n",
        "arrayMarketData = np.asarray(marketData)\n",
        "[mRows, mCols]=arrayMarketData.shape\n",
        "marketReturns = StockReturnsComputing(arrayMarketData, mRows, mCols)\n",
        "\n",
        "beta= []\n",
        "Var = np.var(marketReturns, ddof =1)\n",
        "for i in range(stockColumns):\n",
        "    CovarMat = np.cov(marketReturns[:,0], stockReturns[:, i ])\n",
        "    Covar  = CovarMat[1,0]\n",
        "    beta.append(Covar/Var)\n",
        "\n",
        "print('Asset Betas:  \\n')\n",
        "for data in beta:\n",
        "    print('{:9.3f}'.format(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf_NnVzBnGur",
        "outputId": "98d07d35-6bdf-4b0f-cde6-51b640c2189e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Portfolio stocks\n",
            " ['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'DIS', 'GS', 'HD', 'IBM', 'JPM', 'KO', 'MCD', 'MRK', 'UNH', 'WBA']\n",
            "Asset Betas:  \n",
            "\n",
            "    1.134\n",
            "    1.087\n",
            "    1.392\n",
            "    1.527\n",
            "    1.154\n",
            "    0.767\n",
            "    1.317\n",
            "    0.937\n",
            "    0.976\n",
            "    1.115\n",
            "    0.460\n",
            "    0.554\n",
            "    0.735\n",
            "    0.950\n",
            "    0.850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = np.array([0.09, 0.07, 0.03, 0.02, 0.07, 0.06, 0.04, 0.07, 0.11, \\\n",
        "                    0.08, 0.09, 0.07, 0.05, 0.11, 0.04])\n",
        "assetBeta = np.array([1.13, 1.09, 1.39, 1.53, 1.15, 0.77, 1.32, 0.94, 0.98,\\\n",
        "                      1.12, 0.46, 0.55, 0.74, 0.95, 0.85])\n",
        "\n",
        "meanReturns = np.mean(stockReturns, axis = 0)\n",
        "covReturns = np.cov(stockReturns, rowvar=False)\n",
        "\n",
        "portfolioRisk = np.matmul((np.matmul(weights,covReturns)), np.transpose(weights))\n",
        "\n",
        "annualizedRisk  =   np.sqrt(portfolioRisk*251)\n",
        "\n",
        "portfolioReturn = np.matmul(np.array(meanReturns),weights.T)\n",
        "\n",
        "annualizedReturn = 251*np.array(portfolioReturn)\n",
        "\n",
        "portfolioBeta = np.matmul(assetBeta,weights.T)\n",
        "\n",
        "print(\"\\n Annualized Portfolio Risk: %4.2f\" % annualizedRisk,\"%\")\n",
        "print(\"\\n Annualized Expected Portfolio Return: %4.2f\" % annualizedReturn,\"%\")\n",
        "print(\"\\n Portfolio Beta:%4.2f\" % portfolioBeta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbl2plRSnbCX",
        "outputId": "5f3d4cd5-fcba-4e82-fc96-42b5de12195a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Annualized Portfolio Risk: 12.54 %\n",
            "\n",
            " Annualized Expected Portfolio Return: 14.94 %\n",
            "\n",
            " Portfolio Beta:0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finance Data Wrangling"
      ],
      "metadata": {
        "id": "tlXH0m-sn9GR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def EmptyRowsElimination(dfAssetPrices):\n",
        "\n",
        "    [Rows, Columns] = dfAssetPrices.shape\n",
        "    dFrame = dfAssetPrices.iloc[0:Rows, 0:Columns]\n",
        "\n",
        "    dFClean = dFrame.dropna(axis =0, how ='all')\n",
        "    return dFClean"
      ],
      "metadata": {
        "id": "MTBQRI_YnhqG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#empty rows elimination from stock prices dataset\n",
        "\n",
        "StockFileName = '/content/Lesson2FinDataWranglingSampledata.csv'\n",
        "Rows = 12\n",
        "Columns = 18\n",
        "\n",
        "df = pd.read_csv(StockFileName,  nrows= Rows)\n",
        "\n",
        "assetNames = df.columns[1:Columns+1].tolist()\n",
        "print(assetNames)\n",
        "\n",
        "StockData = df.iloc[0:, 1:]\n",
        "dfClean = EmptyRowsElimination(StockData)\n",
        "print('\\nData cleaning completed!')\n",
        "[rows, cols]=dfClean.shape\n",
        "print('Dimensions of the cleaned dataset', dfClean.shape)\n",
        "print('Cleaned dataset: \\n', dfClean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzkeFdKvoc-G",
        "outputId": "4e67abd4-9ddb-4438-b531-7c647e9818b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['RELIANCE INDUSTRIES LIMITED', 'INFOSYS TECHNOLOGIES LTD', 'ITC LTD', 'BHARTI AIRTEL LIMITED', 'HOUSING DEVELOPMENT FINANCE', 'LARSEN & TOUBRO LIMITED', 'ICICI BANK LTD', 'HDFC BANK LIMITED', 'OIL & NATURAL GAS CORP LTD', 'STATE BANK OF INDIA', 'HINDUSTAN UNILEVER LIMITED', 'BHARAT HEAVY ELECTRICALS', 'NTPC LIMITED', 'TATA CONSULTANCY SVS LTD', 'GAIL INDIA LTD', 'CIPLA LTD', 'GRASIM INDUSTRIES LTD', 'TATA POWER CO LTD']\n",
            "\n",
            "Data cleaning completed!\n",
            "Dimensions of the cleaned dataset (10, 18)\n",
            "Cleaned dataset: \n",
            "     RELIANCE INDUSTRIES LIMITED  INFOSYS TECHNOLOGIES LTD  ITC LTD  \\\n",
            "0                           NaN                       NaN      NaN   \n",
            "1                        245.23                    466.28    49.84   \n",
            "2                        246.77                    462.74    50.05   \n",
            "3                        244.11                    456.34    48.49   \n",
            "4                        241.34                    457.45    49.16   \n",
            "5                        242.15                    464.64    49.97   \n",
            "8                        242.11                    468.44    48.42   \n",
            "9                        247.50                    480.57    48.33   \n",
            "10                       249.80                    479.23    48.70   \n",
            "11                       236.50                    441.28    49.77   \n",
            "\n",
            "    BHARTI AIRTEL LIMITED  HOUSING DEVELOPMENT FINANCE  \\\n",
            "0                   45.00                          NaN   \n",
            "1                   44.15                       338.60   \n",
            "2                   41.20                       337.35   \n",
            "3                   41.40                       334.82   \n",
            "4                   42.45                       330.13   \n",
            "5                   43.45                       335.00   \n",
            "8                   42.65                       336.48   \n",
            "9                   43.55                       340.82   \n",
            "10                  44.30                       333.52   \n",
            "11                  40.90                       340.90   \n",
            "\n",
            "    LARSEN & TOUBRO LIMITED  ICICI BANK LTD  HDFC BANK LIMITED  \\\n",
            "0                       NaN             NaN                NaN   \n",
            "1                     81.53          127.80             248.45   \n",
            "2                     79.56          125.25             234.85   \n",
            "3                     76.94          124.30             236.00   \n",
            "4                     76.57          127.50             236.30   \n",
            "5                     76.25          140.25             247.00   \n",
            "8                     76.27          140.25             243.80   \n",
            "9                     77.47          135.45             237.70   \n",
            "10                    78.12          131.55             235.60   \n",
            "11                    73.34          125.55             235.20   \n",
            "\n",
            "    OIL & NATURAL GAS CORP LTD  STATE BANK OF INDIA  \\\n",
            "0                          NaN                  NaN   \n",
            "1                       152.57               229.09   \n",
            "2                       150.27               226.30   \n",
            "3                       155.37               226.82   \n",
            "4                       152.57               230.41   \n",
            "5                       156.73               227.81   \n",
            "8                       155.37               228.10   \n",
            "9                       161.27               245.55   \n",
            "10                      157.13               238.81   \n",
            "11                      149.13               214.93   \n",
            "\n",
            "    HINDUSTAN UNILEVER LIMITED  BHARAT HEAVY ELECTRICALS  NTPC LIMITED  \\\n",
            "0                          NaN                       NaN           NaN   \n",
            "1                       241.35                     94.33           NaN   \n",
            "2                       241.00                     86.93           NaN   \n",
            "3                       239.95                     85.80           NaN   \n",
            "4                       240.65                     85.30           NaN   \n",
            "5                       240.50                     88.23           NaN   \n",
            "8                       239.10                     86.63           NaN   \n",
            "9                       241.55                     91.45           NaN   \n",
            "10                      246.50                     93.08           NaN   \n",
            "11                      249.80                     84.08           NaN   \n",
            "\n",
            "    TATA CONSULTANCY SVS LTD  GAIL INDIA LTD  CIPLA LTD  \\\n",
            "0                        NaN             NaN        NaN   \n",
            "1                        NaN           54.97      84.12   \n",
            "2                        NaN           53.63      84.32   \n",
            "3                        NaN           52.33      85.21   \n",
            "4                        NaN           52.03      85.22   \n",
            "5                        NaN           51.93      84.92   \n",
            "8                        NaN           49.20      85.30   \n",
            "9                        NaN           51.40      83.87   \n",
            "10                       NaN           49.37      84.10   \n",
            "11                       NaN           47.27      80.44   \n",
            "\n",
            "    GRASIM INDUSTRIES LTD  TATA POWER CO LTD  \n",
            "0                     NaN                NaN  \n",
            "1                  315.51             133.35  \n",
            "2                  311.01             130.30  \n",
            "3                  301.66             126.50  \n",
            "4                  299.76             126.80  \n",
            "5                  299.06             129.90  \n",
            "8                  298.71             130.20  \n",
            "9                  300.96             131.45  \n",
            "10                 307.61             130.80  \n",
            "11                 289.21             119.30  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to fill missing values of daily stock prices\n",
        "#Mandatory requirements: (1) The dataset should have been cleaned of all empty rows\n",
        "#before missing values are filled, and\n",
        "#(2) the opening row of the dataset should not have any empty fields\n",
        "\n",
        "def FillMissingValues(StockPrices):\n",
        "\n",
        "    import numpy as np\n",
        "    print('Fill missing values...')\n",
        "\n",
        "    [rows, cols] = np.where(np.asarray(np.isnan(StockPrices)))\n",
        "\n",
        "    for t in range(rows.size):\n",
        "        i=rows[t]\n",
        "        j = cols[t]\n",
        "        if (i-1) >= 0:\n",
        "            StockPrices.iloc[i,j]= StockPrices.iloc[i-1, j].copy()\n",
        "        else:\n",
        "            print('error')\n",
        "    return StockPrices"
      ],
      "metadata": {
        "id": "kdEwcmANowI6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filling missing values of stock prices dataset\n",
        "\n",
        "StockFileName = '/content/Lesson2MissingValBSE200.csv'\n",
        "Rows = 11\n",
        "Columns = 5\n",
        "\n",
        "df = pd.read_csv(StockFileName,  nrows= Rows)\n",
        "StockData = df.iloc[0:, 1:]\n",
        "\n",
        "assetLabels = df.columns[1:Columns+1].tolist()\n",
        "print('Asset Labels:',assetLabels)\n",
        "\n",
        "stockDataClean = FillMissingValues(StockData)\n",
        "print('Filling missing values completed!\\n')\n",
        "print(stockDataClean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnEOiZkdo29X",
        "outputId": "c14ab01e-84f1-4780-9e8d-d76e0a0c0ac1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asset Labels: ['JINDAL SAW LTD', 'BAJAJ HINDUSTHAN LIMITED', 'LAKSHMI MACHINE WORKS LTD', 'GUJARAT MINERAL DEV CORP LTD', 'MOSER BAER INDIA LTD']\n",
            "Fill missing values...\n",
            "Filling missing values completed!\n",
            "\n",
            "    JINDAL SAW LTD  BAJAJ HINDUSTHAN LIMITED  LAKSHMI MACHINE WORKS LTD  \\\n",
            "0            60.85                      5.10                      69.00   \n",
            "1            60.70                      5.10                      70.00   \n",
            "2            59.50                      5.10                      70.00   \n",
            "3            58.80                      5.06                      69.50   \n",
            "4            57.25                      4.92                      66.49   \n",
            "5            57.05                      5.25                      69.90   \n",
            "6            62.35                      5.25                      70.00   \n",
            "7            66.55                      4.86                      70.00   \n",
            "8            68.50                      4.86                      70.50   \n",
            "9            69.65                      4.86                      70.50   \n",
            "10           65.75                      4.86                      70.00   \n",
            "\n",
            "    GUJARAT MINERAL DEV CORP LTD  MOSER BAER INDIA LTD  \n",
            "0                           4.80                 86.08  \n",
            "1                           4.75                 86.55  \n",
            "2                           4.68                 86.87  \n",
            "3                           4.73                 86.67  \n",
            "4                           4.83                 86.65  \n",
            "5                           5.07                 84.27  \n",
            "6                           5.01                 82.45  \n",
            "7                           4.95                 82.92  \n",
            "8                           4.96                 83.62  \n",
            "9                           4.95                 84.22  \n",
            "10                          4.94                 83.20  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Heuristic Portfolio Selection"
      ],
      "metadata": {
        "id": "uV79oAwepKIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read stock prices from a cleaned DJIA dataset\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "stockFileName = '/content/DJIA_Apr112014_Apr112019.csv'\n",
        "originalRows = 1259\n",
        "originalColumns = 29\n",
        "clusters = 15\n",
        "\n",
        "df = pd.read_csv(stockFileName,  nrows= originalRows)\n",
        "\n",
        "assetLabels = df.columns[1:originalColumns+1].tolist()\n",
        "print(assetLabels)\n",
        "\n",
        "dfStockPrices = df.iloc[0:, 1:]\n",
        "\n",
        "arStockPrices = np.asarray(dfStockPrices)\n",
        "[rows, cols]= arStockPrices.shape\n",
        "print(rows, cols)\n",
        "print(arStockPrices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7wdSjbqo_CF",
        "outputId": "928926c1-80b9-45b3-aa1c-f18826953f23"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'CVX', 'DIS', 'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'KO', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PFE', 'PG', 'TRV', 'UNH', 'UTX', 'V', 'VZ', 'WBA', 'WMT', 'XOM']\n",
            "1259 29\n",
            "[[ 74.230003  84.540001 122.07     ...  64.260002  76.5       96.720001]\n",
            " [ 74.525711  85.5      123.25     ...  65.669998  77.379997  97.860001]\n",
            " [ 73.994286  86.040001 124.269997 ...  66.010002  76.879997  98.68    ]\n",
            " ...\n",
            " [199.5      109.849998 369.040009 ...  54.5       98.690002  81.93    ]\n",
            " [200.619995 110.160004 364.940002 ...  54.509998  99.599998  81.559998]\n",
            " [198.949997 109.849998 370.160004 ...  53.439999 100.800003  81.949997]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function for Stock Returns computing\n",
        "def StockReturnsComputing(StockPrice, Rows, Columns):\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "    StockReturn = np.zeros([Rows-1, Columns])\n",
        "    for j in range(Columns):\n",
        "        for i in range(Rows-1):\n",
        "            StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])\n",
        "\n",
        "    return StockReturn"
      ],
      "metadata": {
        "id": "i36F_mj3pYfp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute daily returns of all stocks in the mini universe\n",
        "arReturns = StockReturnsComputing(arStockPrices, rows, cols)\n",
        "print('Size of the array of daily returns of stocks:\\n', arReturns.shape)\n",
        "print('Array of daily returns of stocks\\n',  arReturns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQskbYuaplpm",
        "outputId": "405500e8-669b-47ca-f588-bd1794d5ffaa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the array of daily returns of stocks:\n",
            " (1258, 29)\n",
            "Array of daily returns of stocks\n",
            " [[ 0.00398367  0.01135556  0.00966658 ...  0.02194205  0.01150323\n",
            "   0.0117866 ]\n",
            " [-0.00713076  0.0063158   0.00827584 ...  0.00517746 -0.00646162\n",
            "   0.00837931]\n",
            " [ 0.0020272   0.01580661  0.01424321 ...  0.00227241  0.00442253\n",
            "   0.01276857]\n",
            " ...\n",
            " [-0.00299853 -0.0076784  -0.01463201 ... -0.01017074 -0.00544191\n",
            "  -0.01289157]\n",
            " [ 0.00561401  0.00282208 -0.01110993 ...  0.00018345  0.00922075\n",
            "  -0.00451607]\n",
            " [-0.00832419 -0.00281414  0.01430373 ... -0.01962941  0.01204824\n",
            "   0.00478174]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute mean returns and variance covariance matrix of returns\n",
        "meanReturns = np.mean(arReturns, axis = 0)\n",
        "print('Mean returns:\\n', meanReturns)\n",
        "covReturns = np.cov(arReturns, rowvar=False)\n",
        "#set precision for printing results\n",
        "np.set_printoptions(precision=5, suppress = True)\n",
        "print('Size of Variance-Covariance matrix of returns:\\n', covReturns.shape)\n",
        "print('Variance-Covariance matrix of returns:\\n', covReturns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuzRVbBFpnW-",
        "outputId": "ee75870d-0536-48e3-820c-4ac3a7f66c45"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean returns:\n",
            " [ 9.02759761e-04  2.91002178e-04  9.96644943e-04  3.86567003e-04\n",
            "  8.09992956e-04  1.55150853e-04  3.97538062e-04  3.31387657e-04\n",
            "  8.47901377e-04 -1.61102228e-04  7.27422090e-04  3.15481134e-04\n",
            "  6.04105771e-04  1.91569684e-04  5.65341938e-04  4.42214370e-04\n",
            "  3.57998589e-04  9.97435940e-04  8.00864357e-04  3.37582842e-04\n",
            "  2.51423106e-04  4.25465919e-04  9.54807585e-04  1.87158182e-04\n",
            "  1.01281343e-03  2.31432075e-04 -1.68527771e-05  2.94624799e-04\n",
            " -6.10160493e-05]\n",
            "Size of Variance-Covariance matrix of returns:\n",
            " (29, 29)\n",
            "Variance-Covariance matrix of returns:\n",
            " [[0.00024 0.00007 0.0001  0.0001  0.0001  0.00007 0.00007 0.0001  0.00007\n",
            "  0.00007 0.00011 0.00005 0.00008 0.00003 0.00005 0.00007 0.00005 0.00012\n",
            "  0.00008 0.00005 0.00004 0.00005 0.00008 0.00007 0.0001  0.00003 0.00007\n",
            "  0.00004 0.00006]\n",
            " [0.00007 0.00016 0.00008 0.0001  0.00007 0.00006 0.00006 0.00011 0.00007\n",
            "  0.00007 0.00007 0.00005 0.0001  0.00003 0.00004 0.00007 0.00006 0.00008\n",
            "  0.00007 0.00005 0.00003 0.00005 0.00007 0.00007 0.00008 0.00003 0.00007\n",
            "  0.00004 0.00005]\n",
            " [0.0001  0.00008 0.00023 0.00013 0.00009 0.00008 0.00007 0.00011 0.00007\n",
            "  0.00008 0.0001  0.00006 0.0001  0.00004 0.00005 0.00009 0.00006 0.00009\n",
            "  0.00008 0.00005 0.00004 0.00006 0.00007 0.00009 0.00009 0.00004 0.00007\n",
            "  0.00005 0.00007]\n",
            " [0.0001  0.0001  0.00013 0.00027 0.0001  0.00012 0.00007 0.00013 0.00008\n",
            "  0.00009 0.00012 0.00005 0.00012 0.00004 0.00005 0.00011 0.00006 0.00011\n",
            "  0.00008 0.00006 0.00004 0.00007 0.00007 0.0001  0.0001  0.00004 0.00007\n",
            "  0.00004 0.00011]\n",
            " [0.0001  0.00007 0.00009 0.0001  0.00018 0.00008 0.00007 0.00009 0.00007\n",
            "  0.00008 0.00012 0.00006 0.00009 0.00004 0.00005 0.00008 0.00006 0.00011\n",
            "  0.00008 0.00006 0.00004 0.00006 0.00007 0.00007 0.00009 0.00005 0.00007\n",
            "  0.00006 0.00007]\n",
            " [0.00007 0.00006 0.00008 0.00012 0.00008 0.00019 0.00006 0.00009 0.00006\n",
            "  0.00007 0.00008 0.00005 0.00009 0.00004 0.00004 0.00007 0.00006 0.00008\n",
            "  0.00005 0.00005 0.00004 0.00006 0.00006 0.00006 0.00007 0.00005 0.00006\n",
            "  0.00004 0.00013]\n",
            " [0.00007 0.00006 0.00007 0.00007 0.00007 0.00006 0.00014 0.00008 0.00006\n",
            "  0.00006 0.00007 0.00004 0.00007 0.00003 0.00004 0.00006 0.00005 0.00007\n",
            "  0.00007 0.00005 0.00004 0.00005 0.00006 0.00005 0.00007 0.00004 0.00006\n",
            "  0.00004 0.00006]\n",
            " [0.0001  0.00011 0.00011 0.00013 0.00009 0.00009 0.00008 0.00021 0.00008\n",
            "  0.00008 0.0001  0.00005 0.00016 0.00003 0.00005 0.00008 0.00007 0.0001\n",
            "  0.00008 0.00006 0.00004 0.00008 0.00008 0.00008 0.0001  0.00004 0.00008\n",
            "  0.00004 0.00008]\n",
            " [0.00007 0.00007 0.00007 0.00008 0.00007 0.00006 0.00006 0.00008 0.00014\n",
            "  0.00006 0.00007 0.00005 0.00008 0.00003 0.00005 0.00006 0.00005 0.00008\n",
            "  0.00008 0.00005 0.00004 0.00005 0.00007 0.00006 0.00008 0.00004 0.00007\n",
            "  0.00006 0.00005]\n",
            " [0.00007 0.00007 0.00008 0.00009 0.00008 0.00007 0.00006 0.00008 0.00006\n",
            "  0.00016 0.00008 0.00005 0.00008 0.00004 0.00004 0.00007 0.00006 0.00009\n",
            "  0.00006 0.00005 0.00004 0.00005 0.00006 0.00007 0.00008 0.00004 0.00005\n",
            "  0.00004 0.00006]\n",
            " [0.00011 0.00007 0.0001  0.00012 0.00012 0.00008 0.00007 0.0001  0.00007\n",
            "  0.00008 0.00025 0.00006 0.00009 0.00004 0.00004 0.00009 0.00006 0.00013\n",
            "  0.00007 0.00006 0.00004 0.00006 0.00007 0.00008 0.00009 0.00005 0.00007\n",
            "  0.00005 0.00007]\n",
            " [0.00005 0.00005 0.00006 0.00005 0.00006 0.00005 0.00004 0.00005 0.00005\n",
            "  0.00005 0.00006 0.0001  0.00005 0.00004 0.00004 0.00006 0.00006 0.00006\n",
            "  0.00005 0.00006 0.00004 0.00005 0.00006 0.00005 0.00005 0.00004 0.00006\n",
            "  0.00004 0.00005]\n",
            " [0.00008 0.0001  0.0001  0.00012 0.00009 0.00009 0.00007 0.00016 0.00008\n",
            "  0.00008 0.00009 0.00005 0.00017 0.00003 0.00005 0.00008 0.00007 0.00009\n",
            "  0.00007 0.00006 0.00004 0.00008 0.00008 0.00008 0.00009 0.00004 0.00007\n",
            "  0.00004 0.00008]\n",
            " [0.00003 0.00003 0.00004 0.00004 0.00004 0.00004 0.00003 0.00003 0.00003\n",
            "  0.00004 0.00004 0.00004 0.00003 0.00008 0.00004 0.00004 0.00004 0.00004\n",
            "  0.00004 0.00003 0.00005 0.00004 0.00003 0.00003 0.00004 0.00004 0.00004\n",
            "  0.00003 0.00003]\n",
            " [0.00005 0.00004 0.00005 0.00005 0.00005 0.00004 0.00004 0.00005 0.00005\n",
            "  0.00004 0.00004 0.00004 0.00005 0.00004 0.00011 0.00004 0.00004 0.00006\n",
            "  0.00005 0.00003 0.00004 0.00004 0.00004 0.00004 0.00005 0.00004 0.00004\n",
            "  0.00004 0.00004]\n",
            " [0.00007 0.00007 0.00009 0.00011 0.00008 0.00007 0.00006 0.00008 0.00006\n",
            "  0.00007 0.00009 0.00006 0.00008 0.00004 0.00004 0.00012 0.00006 0.00008\n",
            "  0.00006 0.00006 0.00004 0.00006 0.00006 0.00007 0.00007 0.00004 0.00006\n",
            "  0.00004 0.00006]\n",
            " [0.00005 0.00006 0.00006 0.00006 0.00006 0.00006 0.00005 0.00007 0.00005\n",
            "  0.00006 0.00006 0.00006 0.00007 0.00004 0.00004 0.00006 0.00015 0.00006\n",
            "  0.00005 0.00008 0.00004 0.00005 0.00006 0.00005 0.00006 0.00005 0.00006\n",
            "  0.00005 0.00006]\n",
            " [0.00012 0.00008 0.00009 0.00011 0.00011 0.00008 0.00007 0.0001  0.00008\n",
            "  0.00009 0.00013 0.00006 0.00009 0.00004 0.00006 0.00008 0.00006 0.00021\n",
            "  0.00008 0.00007 0.00005 0.00006 0.00008 0.00008 0.00012 0.00005 0.00008\n",
            "  0.00005 0.00007]\n",
            " [0.00008 0.00007 0.00008 0.00008 0.00008 0.00005 0.00007 0.00008 0.00008\n",
            "  0.00006 0.00007 0.00005 0.00007 0.00004 0.00005 0.00006 0.00005 0.00008\n",
            "  0.00022 0.00005 0.00004 0.00005 0.00007 0.00006 0.00008 0.00004 0.00007\n",
            "  0.00005 0.00005]\n",
            " [0.00005 0.00005 0.00005 0.00006 0.00006 0.00005 0.00005 0.00006 0.00005\n",
            "  0.00005 0.00006 0.00006 0.00006 0.00003 0.00003 0.00006 0.00008 0.00007\n",
            "  0.00005 0.00012 0.00004 0.00005 0.00007 0.00005 0.00006 0.00004 0.00006\n",
            "  0.00004 0.00005]\n",
            " [0.00004 0.00003 0.00004 0.00004 0.00004 0.00004 0.00004 0.00004 0.00004\n",
            "  0.00004 0.00004 0.00004 0.00004 0.00005 0.00004 0.00004 0.00004 0.00005\n",
            "  0.00004 0.00004 0.00009 0.00004 0.00004 0.00004 0.00004 0.00004 0.00004\n",
            "  0.00004 0.00004]\n",
            " [0.00005 0.00005 0.00006 0.00007 0.00006 0.00006 0.00005 0.00008 0.00005\n",
            "  0.00005 0.00006 0.00005 0.00008 0.00004 0.00004 0.00006 0.00005 0.00006\n",
            "  0.00005 0.00005 0.00004 0.00011 0.00006 0.00006 0.00006 0.00004 0.00006\n",
            "  0.00004 0.00005]\n",
            " [0.00008 0.00007 0.00007 0.00007 0.00007 0.00006 0.00006 0.00008 0.00007\n",
            "  0.00006 0.00007 0.00006 0.00008 0.00003 0.00004 0.00006 0.00006 0.00008\n",
            "  0.00007 0.00007 0.00004 0.00006 0.00017 0.00006 0.00007 0.00004 0.00008\n",
            "  0.00005 0.00005]\n",
            " [0.00007 0.00007 0.00009 0.0001  0.00007 0.00006 0.00005 0.00008 0.00006\n",
            "  0.00007 0.00008 0.00005 0.00008 0.00003 0.00004 0.00007 0.00005 0.00008\n",
            "  0.00006 0.00005 0.00004 0.00006 0.00006 0.00013 0.00007 0.00004 0.00006\n",
            "  0.00004 0.00006]\n",
            " [0.0001  0.00008 0.00009 0.0001  0.00009 0.00007 0.00007 0.0001  0.00008\n",
            "  0.00008 0.00009 0.00005 0.00009 0.00004 0.00005 0.00007 0.00006 0.00012\n",
            "  0.00008 0.00006 0.00004 0.00006 0.00007 0.00007 0.00017 0.00003 0.00007\n",
            "  0.00004 0.00006]\n",
            " [0.00003 0.00003 0.00004 0.00004 0.00005 0.00005 0.00004 0.00004 0.00004\n",
            "  0.00004 0.00005 0.00004 0.00004 0.00004 0.00004 0.00004 0.00005 0.00005\n",
            "  0.00004 0.00004 0.00004 0.00004 0.00004 0.00004 0.00003 0.00012 0.00005\n",
            "  0.00004 0.00004]\n",
            " [0.00007 0.00007 0.00007 0.00007 0.00007 0.00006 0.00006 0.00008 0.00007\n",
            "  0.00005 0.00007 0.00006 0.00007 0.00004 0.00004 0.00006 0.00006 0.00008\n",
            "  0.00007 0.00006 0.00004 0.00006 0.00008 0.00006 0.00007 0.00005 0.00026\n",
            "  0.00006 0.00005]\n",
            " [0.00004 0.00004 0.00005 0.00004 0.00006 0.00004 0.00004 0.00004 0.00006\n",
            "  0.00004 0.00005 0.00004 0.00004 0.00003 0.00004 0.00004 0.00005 0.00005\n",
            "  0.00005 0.00004 0.00004 0.00004 0.00005 0.00004 0.00004 0.00004 0.00006\n",
            "  0.00015 0.00004]\n",
            " [0.00006 0.00005 0.00007 0.00011 0.00007 0.00013 0.00006 0.00008 0.00005\n",
            "  0.00006 0.00007 0.00005 0.00008 0.00003 0.00004 0.00006 0.00006 0.00007\n",
            "  0.00005 0.00005 0.00004 0.00005 0.00005 0.00006 0.00006 0.00004 0.00005\n",
            "  0.00004 0.00014]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare asset parameters for k-means clustering\n",
        "#reshape for concatenation\n",
        "meanReturns = meanReturns.reshape(len(meanReturns),1)\n",
        "assetParameters = np.concatenate([meanReturns, covReturns], axis = 1)\n",
        "print('Size of the asset parameters for clustering:\\n', assetParameters.shape)\n",
        "print('Asset parameters for clustering:\\n', assetParameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP4E-8KGpqVC",
        "outputId": "281d10a4-0a54-44d4-89ab-e82b559f380e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the asset parameters for clustering:\n",
            " (29, 30)\n",
            "Asset parameters for clustering:\n",
            " [[ 0.0009   0.00024  0.00007  0.0001   0.0001   0.0001   0.00007  0.00007\n",
            "   0.0001   0.00007  0.00007  0.00011  0.00005  0.00008  0.00003  0.00005\n",
            "   0.00007  0.00005  0.00012  0.00008  0.00005  0.00004  0.00005  0.00008\n",
            "   0.00007  0.0001   0.00003  0.00007  0.00004  0.00006]\n",
            " [ 0.00029  0.00007  0.00016  0.00008  0.0001   0.00007  0.00006  0.00006\n",
            "   0.00011  0.00007  0.00007  0.00007  0.00005  0.0001   0.00003  0.00004\n",
            "   0.00007  0.00006  0.00008  0.00007  0.00005  0.00003  0.00005  0.00007\n",
            "   0.00007  0.00008  0.00003  0.00007  0.00004  0.00005]\n",
            " [ 0.001    0.0001   0.00008  0.00023  0.00013  0.00009  0.00008  0.00007\n",
            "   0.00011  0.00007  0.00008  0.0001   0.00006  0.0001   0.00004  0.00005\n",
            "   0.00009  0.00006  0.00009  0.00008  0.00005  0.00004  0.00006  0.00007\n",
            "   0.00009  0.00009  0.00004  0.00007  0.00005  0.00007]\n",
            " [ 0.00039  0.0001   0.0001   0.00013  0.00027  0.0001   0.00012  0.00007\n",
            "   0.00013  0.00008  0.00009  0.00012  0.00005  0.00012  0.00004  0.00005\n",
            "   0.00011  0.00006  0.00011  0.00008  0.00006  0.00004  0.00007  0.00007\n",
            "   0.0001   0.0001   0.00004  0.00007  0.00004  0.00011]\n",
            " [ 0.00081  0.0001   0.00007  0.00009  0.0001   0.00018  0.00008  0.00007\n",
            "   0.00009  0.00007  0.00008  0.00012  0.00006  0.00009  0.00004  0.00005\n",
            "   0.00008  0.00006  0.00011  0.00008  0.00006  0.00004  0.00006  0.00007\n",
            "   0.00007  0.00009  0.00005  0.00007  0.00006  0.00007]\n",
            " [ 0.00016  0.00007  0.00006  0.00008  0.00012  0.00008  0.00019  0.00006\n",
            "   0.00009  0.00006  0.00007  0.00008  0.00005  0.00009  0.00004  0.00004\n",
            "   0.00007  0.00006  0.00008  0.00005  0.00005  0.00004  0.00006  0.00006\n",
            "   0.00006  0.00007  0.00005  0.00006  0.00004  0.00013]\n",
            " [ 0.0004   0.00007  0.00006  0.00007  0.00007  0.00007  0.00006  0.00014\n",
            "   0.00008  0.00006  0.00006  0.00007  0.00004  0.00007  0.00003  0.00004\n",
            "   0.00006  0.00005  0.00007  0.00007  0.00005  0.00004  0.00005  0.00006\n",
            "   0.00005  0.00007  0.00004  0.00006  0.00004  0.00006]\n",
            " [ 0.00033  0.0001   0.00011  0.00011  0.00013  0.00009  0.00009  0.00008\n",
            "   0.00021  0.00008  0.00008  0.0001   0.00005  0.00016  0.00003  0.00005\n",
            "   0.00008  0.00007  0.0001   0.00008  0.00006  0.00004  0.00008  0.00008\n",
            "   0.00008  0.0001   0.00004  0.00008  0.00004  0.00008]\n",
            " [ 0.00085  0.00007  0.00007  0.00007  0.00008  0.00007  0.00006  0.00006\n",
            "   0.00008  0.00014  0.00006  0.00007  0.00005  0.00008  0.00003  0.00005\n",
            "   0.00006  0.00005  0.00008  0.00008  0.00005  0.00004  0.00005  0.00007\n",
            "   0.00006  0.00008  0.00004  0.00007  0.00006  0.00005]\n",
            " [-0.00016  0.00007  0.00007  0.00008  0.00009  0.00008  0.00007  0.00006\n",
            "   0.00008  0.00006  0.00016  0.00008  0.00005  0.00008  0.00004  0.00004\n",
            "   0.00007  0.00006  0.00009  0.00006  0.00005  0.00004  0.00005  0.00006\n",
            "   0.00007  0.00008  0.00004  0.00005  0.00004  0.00006]\n",
            " [ 0.00073  0.00011  0.00007  0.0001   0.00012  0.00012  0.00008  0.00007\n",
            "   0.0001   0.00007  0.00008  0.00025  0.00006  0.00009  0.00004  0.00004\n",
            "   0.00009  0.00006  0.00013  0.00007  0.00006  0.00004  0.00006  0.00007\n",
            "   0.00008  0.00009  0.00005  0.00007  0.00005  0.00007]\n",
            " [ 0.00032  0.00005  0.00005  0.00006  0.00005  0.00006  0.00005  0.00004\n",
            "   0.00005  0.00005  0.00005  0.00006  0.0001   0.00005  0.00004  0.00004\n",
            "   0.00006  0.00006  0.00006  0.00005  0.00006  0.00004  0.00005  0.00006\n",
            "   0.00005  0.00005  0.00004  0.00006  0.00004  0.00005]\n",
            " [ 0.0006   0.00008  0.0001   0.0001   0.00012  0.00009  0.00009  0.00007\n",
            "   0.00016  0.00008  0.00008  0.00009  0.00005  0.00017  0.00003  0.00005\n",
            "   0.00008  0.00007  0.00009  0.00007  0.00006  0.00004  0.00008  0.00008\n",
            "   0.00008  0.00009  0.00004  0.00007  0.00004  0.00008]\n",
            " [ 0.00019  0.00003  0.00003  0.00004  0.00004  0.00004  0.00004  0.00003\n",
            "   0.00003  0.00003  0.00004  0.00004  0.00004  0.00003  0.00008  0.00004\n",
            "   0.00004  0.00004  0.00004  0.00004  0.00003  0.00005  0.00004  0.00003\n",
            "   0.00003  0.00004  0.00004  0.00004  0.00003  0.00003]\n",
            " [ 0.00057  0.00005  0.00004  0.00005  0.00005  0.00005  0.00004  0.00004\n",
            "   0.00005  0.00005  0.00004  0.00004  0.00004  0.00005  0.00004  0.00011\n",
            "   0.00004  0.00004  0.00006  0.00005  0.00003  0.00004  0.00004  0.00004\n",
            "   0.00004  0.00005  0.00004  0.00004  0.00004  0.00004]\n",
            " [ 0.00044  0.00007  0.00007  0.00009  0.00011  0.00008  0.00007  0.00006\n",
            "   0.00008  0.00006  0.00007  0.00009  0.00006  0.00008  0.00004  0.00004\n",
            "   0.00012  0.00006  0.00008  0.00006  0.00006  0.00004  0.00006  0.00006\n",
            "   0.00007  0.00007  0.00004  0.00006  0.00004  0.00006]\n",
            " [ 0.00036  0.00005  0.00006  0.00006  0.00006  0.00006  0.00006  0.00005\n",
            "   0.00007  0.00005  0.00006  0.00006  0.00006  0.00007  0.00004  0.00004\n",
            "   0.00006  0.00015  0.00006  0.00005  0.00008  0.00004  0.00005  0.00006\n",
            "   0.00005  0.00006  0.00005  0.00006  0.00005  0.00006]\n",
            " [ 0.001    0.00012  0.00008  0.00009  0.00011  0.00011  0.00008  0.00007\n",
            "   0.0001   0.00008  0.00009  0.00013  0.00006  0.00009  0.00004  0.00006\n",
            "   0.00008  0.00006  0.00021  0.00008  0.00007  0.00005  0.00006  0.00008\n",
            "   0.00008  0.00012  0.00005  0.00008  0.00005  0.00007]\n",
            " [ 0.0008   0.00008  0.00007  0.00008  0.00008  0.00008  0.00005  0.00007\n",
            "   0.00008  0.00008  0.00006  0.00007  0.00005  0.00007  0.00004  0.00005\n",
            "   0.00006  0.00005  0.00008  0.00022  0.00005  0.00004  0.00005  0.00007\n",
            "   0.00006  0.00008  0.00004  0.00007  0.00005  0.00005]\n",
            " [ 0.00034  0.00005  0.00005  0.00005  0.00006  0.00006  0.00005  0.00005\n",
            "   0.00006  0.00005  0.00005  0.00006  0.00006  0.00006  0.00003  0.00003\n",
            "   0.00006  0.00008  0.00007  0.00005  0.00012  0.00004  0.00005  0.00007\n",
            "   0.00005  0.00006  0.00004  0.00006  0.00004  0.00005]\n",
            " [ 0.00025  0.00004  0.00003  0.00004  0.00004  0.00004  0.00004  0.00004\n",
            "   0.00004  0.00004  0.00004  0.00004  0.00004  0.00004  0.00005  0.00004\n",
            "   0.00004  0.00004  0.00005  0.00004  0.00004  0.00009  0.00004  0.00004\n",
            "   0.00004  0.00004  0.00004  0.00004  0.00004  0.00004]\n",
            " [ 0.00043  0.00005  0.00005  0.00006  0.00007  0.00006  0.00006  0.00005\n",
            "   0.00008  0.00005  0.00005  0.00006  0.00005  0.00008  0.00004  0.00004\n",
            "   0.00006  0.00005  0.00006  0.00005  0.00005  0.00004  0.00011  0.00006\n",
            "   0.00006  0.00006  0.00004  0.00006  0.00004  0.00005]\n",
            " [ 0.00095  0.00008  0.00007  0.00007  0.00007  0.00007  0.00006  0.00006\n",
            "   0.00008  0.00007  0.00006  0.00007  0.00006  0.00008  0.00003  0.00004\n",
            "   0.00006  0.00006  0.00008  0.00007  0.00007  0.00004  0.00006  0.00017\n",
            "   0.00006  0.00007  0.00004  0.00008  0.00005  0.00005]\n",
            " [ 0.00019  0.00007  0.00007  0.00009  0.0001   0.00007  0.00006  0.00005\n",
            "   0.00008  0.00006  0.00007  0.00008  0.00005  0.00008  0.00003  0.00004\n",
            "   0.00007  0.00005  0.00008  0.00006  0.00005  0.00004  0.00006  0.00006\n",
            "   0.00013  0.00007  0.00004  0.00006  0.00004  0.00006]\n",
            " [ 0.00101  0.0001   0.00008  0.00009  0.0001   0.00009  0.00007  0.00007\n",
            "   0.0001   0.00008  0.00008  0.00009  0.00005  0.00009  0.00004  0.00005\n",
            "   0.00007  0.00006  0.00012  0.00008  0.00006  0.00004  0.00006  0.00007\n",
            "   0.00007  0.00017  0.00003  0.00007  0.00004  0.00006]\n",
            " [ 0.00023  0.00003  0.00003  0.00004  0.00004  0.00005  0.00005  0.00004\n",
            "   0.00004  0.00004  0.00004  0.00005  0.00004  0.00004  0.00004  0.00004\n",
            "   0.00004  0.00005  0.00005  0.00004  0.00004  0.00004  0.00004  0.00004\n",
            "   0.00004  0.00003  0.00012  0.00005  0.00004  0.00004]\n",
            " [-0.00002  0.00007  0.00007  0.00007  0.00007  0.00007  0.00006  0.00006\n",
            "   0.00008  0.00007  0.00005  0.00007  0.00006  0.00007  0.00004  0.00004\n",
            "   0.00006  0.00006  0.00008  0.00007  0.00006  0.00004  0.00006  0.00008\n",
            "   0.00006  0.00007  0.00005  0.00026  0.00006  0.00005]\n",
            " [ 0.00029  0.00004  0.00004  0.00005  0.00004  0.00006  0.00004  0.00004\n",
            "   0.00004  0.00006  0.00004  0.00005  0.00004  0.00004  0.00003  0.00004\n",
            "   0.00004  0.00005  0.00005  0.00005  0.00004  0.00004  0.00004  0.00005\n",
            "   0.00004  0.00004  0.00004  0.00006  0.00015  0.00004]\n",
            " [-0.00006  0.00006  0.00005  0.00007  0.00011  0.00007  0.00013  0.00006\n",
            "   0.00008  0.00005  0.00006  0.00007  0.00005  0.00008  0.00003  0.00004\n",
            "   0.00006  0.00006  0.00007  0.00005  0.00005  0.00004  0.00005  0.00005\n",
            "   0.00006  0.00006  0.00004  0.00005  0.00004  0.00014]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kmeans clustering of assets using the characteristic vector of\n",
        "#mean return and variance-covariance vector of returns\n",
        "\n",
        "assetsCluster= KMeans(algorithm='auto',  max_iter=600, n_clusters=clusters)\n",
        "print('Clustering of assets completed!')\n",
        "assetsCluster.fit(assetParameters)\n",
        "centroids = assetsCluster.cluster_centers_\n",
        "labels = assetsCluster.labels_\n",
        "\n",
        "print('Centroids:\\n', centroids)\n",
        "print('Labels:\\n', labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVKGJ891ptwd",
        "outputId": "5f5ffc61-cd9e-496a-d2a2-30d7095b71cb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clustering of assets completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1420: FutureWarning: algorithm='auto' is deprecated, it will be removed in 1.3. Using 'lloyd' instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centroids:\n",
            " [[ 0.00082  0.00008  0.00007  0.00008  0.00008  0.00008  0.00006  0.00006\n",
            "   0.00008  0.00011  0.00006  0.00007  0.00005  0.00007  0.00004  0.00005\n",
            "   0.00006  0.00005  0.00008  0.00015  0.00005  0.00004  0.00005  0.00007\n",
            "   0.00006  0.00008  0.00004  0.00007  0.00005  0.00005]\n",
            " [ 0.00024  0.00004  0.00003  0.00004  0.00004  0.00005  0.00004  0.00004\n",
            "   0.00004  0.00004  0.00004  0.00004  0.00004  0.00004  0.00005  0.00004\n",
            "   0.00004  0.00004  0.00005  0.00004  0.00004  0.00005  0.00004  0.00004\n",
            "   0.00004  0.00004  0.00006  0.00005  0.00007  0.00004]\n",
            " [ 0.00021  0.00007  0.0001   0.00008  0.00011  0.00007  0.00011  0.00006\n",
            "   0.00009  0.00006  0.00007  0.00008  0.00005  0.00009  0.00003  0.00004\n",
            "   0.00007  0.00005  0.00008  0.00006  0.00005  0.00004  0.00006  0.00006\n",
            "   0.00009  0.00008  0.00004  0.00006  0.00004  0.00008]\n",
            " [ 0.00042  0.00006  0.00006  0.00007  0.00008  0.00007  0.00006  0.00008\n",
            "   0.00008  0.00006  0.00006  0.00007  0.00005  0.00008  0.00004  0.00004\n",
            "   0.00008  0.00005  0.00007  0.00006  0.00005  0.00004  0.00007  0.00006\n",
            "   0.00006  0.00007  0.00004  0.00006  0.00004  0.00006]\n",
            " [ 0.001    0.0001   0.00008  0.00023  0.00013  0.00009  0.00008  0.00007\n",
            "   0.00011  0.00007  0.00008  0.0001   0.00006  0.0001   0.00004  0.00005\n",
            "   0.00009  0.00006  0.00009  0.00008  0.00005  0.00004  0.00006  0.00007\n",
            "   0.00009  0.00009  0.00004  0.00007  0.00005  0.00007]\n",
            " [-0.00002  0.00007  0.00007  0.00007  0.00007  0.00007  0.00006  0.00006\n",
            "   0.00008  0.00007  0.00005  0.00007  0.00006  0.00007  0.00004  0.00004\n",
            "   0.00006  0.00006  0.00008  0.00007  0.00006  0.00004  0.00006  0.00008\n",
            "   0.00006  0.00007  0.00005  0.00026  0.00006  0.00005]\n",
            " [-0.00011  0.00007  0.00006  0.00008  0.0001   0.00008  0.0001   0.00006\n",
            "   0.00008  0.00006  0.00011  0.00008  0.00005  0.00008  0.00004  0.00004\n",
            "   0.00007  0.00006  0.00008  0.00005  0.00005  0.00004  0.00005  0.00005\n",
            "   0.00006  0.00007  0.00004  0.00005  0.00004  0.0001 ]\n",
            " [ 0.00039  0.0001   0.0001   0.00013  0.00027  0.0001   0.00012  0.00007\n",
            "   0.00013  0.00008  0.00009  0.00012  0.00005  0.00012  0.00004  0.00005\n",
            "   0.00011  0.00006  0.00011  0.00008  0.00006  0.00004  0.00007  0.00007\n",
            "   0.0001   0.0001   0.00004  0.00007  0.00004  0.00011]\n",
            " [ 0.00077  0.0001   0.00007  0.00009  0.00011  0.00015  0.00008  0.00007\n",
            "   0.0001   0.00007  0.00008  0.00018  0.00006  0.00009  0.00004  0.00005\n",
            "   0.00008  0.00006  0.00012  0.00008  0.00006  0.00004  0.00006  0.00007\n",
            "   0.00008  0.00009  0.00005  0.00007  0.00005  0.00007]\n",
            " [ 0.00095  0.00008  0.00007  0.00007  0.00007  0.00007  0.00006  0.00006\n",
            "   0.00008  0.00007  0.00006  0.00007  0.00006  0.00008  0.00003  0.00004\n",
            "   0.00006  0.00006  0.00008  0.00007  0.00007  0.00004  0.00006  0.00017\n",
            "   0.00006  0.00007  0.00004  0.00008  0.00005  0.00005]\n",
            " [ 0.00097  0.00015  0.00008  0.00009  0.0001   0.0001   0.00007  0.00007\n",
            "   0.0001   0.00008  0.00008  0.00011  0.00005  0.00009  0.00004  0.00005\n",
            "   0.00008  0.00006  0.00015  0.00008  0.00006  0.00004  0.00006  0.00008\n",
            "   0.00007  0.00013  0.00004  0.00007  0.00005  0.00006]\n",
            " [ 0.00033  0.0001   0.00011  0.00011  0.00013  0.00009  0.00009  0.00008\n",
            "   0.00021  0.00008  0.00008  0.0001   0.00005  0.00016  0.00003  0.00005\n",
            "   0.00008  0.00007  0.0001   0.00008  0.00006  0.00004  0.00008  0.00008\n",
            "   0.00008  0.0001   0.00004  0.00008  0.00004  0.00008]\n",
            " [ 0.0006   0.00008  0.0001   0.0001   0.00012  0.00009  0.00009  0.00007\n",
            "   0.00016  0.00008  0.00008  0.00009  0.00005  0.00017  0.00003  0.00005\n",
            "   0.00008  0.00007  0.00009  0.00007  0.00006  0.00004  0.00008  0.00008\n",
            "   0.00008  0.00009  0.00004  0.00007  0.00004  0.00008]\n",
            " [ 0.00057  0.00005  0.00004  0.00005  0.00005  0.00005  0.00004  0.00004\n",
            "   0.00005  0.00005  0.00004  0.00004  0.00004  0.00005  0.00004  0.00011\n",
            "   0.00004  0.00004  0.00006  0.00005  0.00003  0.00004  0.00004  0.00004\n",
            "   0.00004  0.00005  0.00004  0.00004  0.00004  0.00004]\n",
            " [ 0.00034  0.00005  0.00005  0.00006  0.00006  0.00006  0.00005  0.00004\n",
            "   0.00006  0.00005  0.00005  0.00006  0.00007  0.00006  0.00004  0.00004\n",
            "   0.00006  0.0001   0.00006  0.00005  0.00009  0.00004  0.00005  0.00006\n",
            "   0.00005  0.00006  0.00004  0.00006  0.00004  0.00005]]\n",
            "Labels:\n",
            " [10  2  4  7  8  2  3 11  0  6  8 14 12  1 13  3 14 10  0 14  1  3  9  2\n",
            " 10  1  5  1  6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fixing asset labels to cluster points\n",
        "print('Stocks in each of the clusters:\\n',)\n",
        "assets = np.array(assetLabels)\n",
        "for i in range(clusters):\n",
        "    print('Cluster', i+1)\n",
        "    clt  = np.where(labels == i)\n",
        "    assetsCluster = assets[clt]\n",
        "    print(assetsCluster)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhiqVwSApxl7",
        "outputId": "31654168-95ae-4b28-cc6d-15a1c8365dba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stocks in each of the clusters:\n",
            "\n",
            "Cluster 1\n",
            "['HD' 'NKE']\n",
            "Cluster 2\n",
            "['KO' 'PG' 'VZ' 'WMT']\n",
            "Cluster 3\n",
            "['AXP' 'CVX' 'UTX']\n",
            "Cluster 4\n",
            "['DIS' 'MMM' 'TRV']\n",
            "Cluster 5\n",
            "['BA']\n",
            "Cluster 6\n",
            "['WBA']\n",
            "Cluster 7\n",
            "['IBM' 'XOM']\n",
            "Cluster 8\n",
            "['CAT']\n",
            "Cluster 9\n",
            "['CSCO' 'INTC']\n",
            "Cluster 10\n",
            "['UNH']\n",
            "Cluster 11\n",
            "['AAPL' 'MSFT' 'V']\n",
            "Cluster 12\n",
            "['GS']\n",
            "Cluster 13\n",
            "['JPM']\n",
            "Cluster 14\n",
            "['MCD']\n",
            "Cluster 15\n",
            "['JNJ' 'MRK' 'PFE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traditional Methods for Portfolio Construction"
      ],
      "metadata": {
        "id": "FgWibcFxp8ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read k portfolio 1 dataset comprising 15 stocks\n",
        "\n",
        "StockFileName = '/content/DJIA_Apr112014_Apr112019_kpf1.csv'\n",
        "Rows = 1259\n",
        "Columns = 15\n",
        "\n",
        "df = pd.read_csv(StockFileName,  nrows= Rows)\n",
        "\n",
        "assetLabels = df.columns[1:Columns+1].tolist()\n",
        "print('k-portfolio 1 asset labels:\\n', assetLabels)\n",
        "\n",
        "dfStockPrices = df.iloc[1:, 1:]\n",
        "\n",
        "arStockPrices = np.asarray(dfStockPrices)\n",
        "[rows, cols]= arStockPrices.shape\n",
        "print('k-portfolio 1 dataset size:\\n', rows, cols)\n",
        "print('k-portfolio 1 stock prices:\\n', arStockPrices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4rAZyDFp019",
        "outputId": "bb021927-3c5c-49d3-b3dd-179ec4f5bd28"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-portfolio 1 asset labels:\n",
            " ['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'DIS', 'GS', 'HD', 'IBM', 'JPM', 'KO', 'MCD', 'MRK', 'UNH', 'WBA']\n",
            "k-portfolio 1 dataset size:\n",
            " 1258 15\n",
            "k-portfolio 1 stock prices:\n",
            " [[ 74.52571  85.5     123.25    ...  55.57     79.18     65.67   ]\n",
            " [ 73.99429  86.04    124.27    ...  56.05     79.51     66.01   ]\n",
            " [ 74.14429  87.4     126.04    ...  56.26     78.19     66.16   ]\n",
            " ...\n",
            " [199.5     109.85    369.04001 ...  80.8     248.78999  54.5    ]\n",
            " [200.61999 110.16    364.94    ...  80.82    246.03     54.51   ]\n",
            " [198.95    109.85    370.16    ...  79.84    235.42     53.44   ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to compute stock returns\n",
        "def StockReturnsComputing(StockPrice, Rows, Columns):\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "    StockReturn = np.zeros([Rows-1, Columns])\n",
        "    for j in range(Columns):\n",
        "        for i in range(Rows-1):\n",
        "            StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])\n",
        "\n",
        "    return StockReturn"
      ],
      "metadata": {
        "id": "Z10Uzm8i8Kxc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute asset returns\n",
        "arReturns = StockReturnsComputing(arStockPrices, rows, cols)\n",
        "print('k-portfolio 1 returns:\\n', arReturns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2C3NvK88Pcp",
        "outputId": "200786b6-f1da-4994-c08c-87e0a05093c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-portfolio 1 returns:\n",
            " [[-0.00713  0.00632  0.00828 ...  0.00864  0.00417  0.00518]\n",
            " [ 0.00203  0.01581  0.01424 ...  0.00375 -0.0166   0.00227]\n",
            " [ 0.01143 -0.0135   0.01492 ...  0.00373 -0.03082  0.00892]\n",
            " ...\n",
            " [-0.003   -0.00768 -0.01463 ... -0.00185  0.00016 -0.01017]\n",
            " [ 0.00561  0.00282 -0.01111 ...  0.00025 -0.01109  0.00018]\n",
            " [-0.00832 -0.00281  0.0143  ... -0.01213 -0.04312 -0.01963]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute mean returns and variance covariance matrix of returns\n",
        "\n",
        "np.set_printoptions(precision=5, suppress = True)\n",
        "\n",
        "meanReturns = np.mean(arReturns, axis = 0)\n",
        "print('Mean returns of k-portfolio 1:\\n', meanReturns)\n",
        "covReturns = np.cov(arReturns, rowvar=False)\n",
        "print('\\nVariance-Covariance matrix of returns of k-portfolio 1: \\n')\n",
        "print('Size  ', covReturns.shape, '\\n', covReturns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JgdkaaJ8RD3",
        "outputId": "162e803f-a551-4d01-be15-802e0e8a7080"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean returns of k-portfolio 1:\n",
            " [ 0.0009   0.00028  0.00099  0.00038  0.0008   0.00039  0.00032  0.00085\n",
            " -0.00017  0.00061  0.00019  0.00056  0.00036  0.00095 -0.00003]\n",
            "\n",
            "Variance-Covariance matrix of returns of k-portfolio 1: \n",
            "\n",
            "Size   (15, 15) \n",
            " [[0.00024 0.00007 0.0001  0.0001  0.0001  0.00007 0.0001  0.00007 0.00007\n",
            "  0.00008 0.00003 0.00005 0.00005 0.00008 0.00007]\n",
            " [0.00007 0.00016 0.00008 0.00009 0.00007 0.00006 0.00011 0.00007 0.00007\n",
            "  0.0001  0.00003 0.00003 0.00006 0.00007 0.00007]\n",
            " [0.0001  0.00008 0.00023 0.00013 0.00009 0.00007 0.00011 0.00007 0.00008\n",
            "  0.0001  0.00004 0.00005 0.00006 0.00007 0.00007]\n",
            " [0.0001  0.00009 0.00013 0.00027 0.0001  0.00007 0.00013 0.00008 0.00009\n",
            "  0.00012 0.00004 0.00005 0.00006 0.00007 0.00007]\n",
            " [0.0001  0.00007 0.00009 0.0001  0.00018 0.00007 0.00009 0.00007 0.00008\n",
            "  0.00009 0.00004 0.00005 0.00006 0.00007 0.00007]\n",
            " [0.00007 0.00006 0.00007 0.00007 0.00007 0.00014 0.00008 0.00006 0.00006\n",
            "  0.00007 0.00003 0.00004 0.00005 0.00006 0.00006]\n",
            " [0.0001  0.00011 0.00011 0.00013 0.00009 0.00008 0.00021 0.00008 0.00008\n",
            "  0.00016 0.00003 0.00005 0.00007 0.00008 0.00008]\n",
            " [0.00007 0.00007 0.00007 0.00008 0.00007 0.00006 0.00008 0.00014 0.00006\n",
            "  0.00008 0.00003 0.00005 0.00005 0.00007 0.00007]\n",
            " [0.00007 0.00007 0.00008 0.00009 0.00008 0.00006 0.00008 0.00006 0.00016\n",
            "  0.00008 0.00004 0.00004 0.00006 0.00006 0.00005]\n",
            " [0.00008 0.0001  0.0001  0.00012 0.00009 0.00007 0.00016 0.00008 0.00008\n",
            "  0.00017 0.00003 0.00005 0.00007 0.00008 0.00007]\n",
            " [0.00003 0.00003 0.00004 0.00004 0.00004 0.00003 0.00003 0.00003 0.00004\n",
            "  0.00003 0.00008 0.00004 0.00004 0.00003 0.00004]\n",
            " [0.00005 0.00003 0.00005 0.00005 0.00005 0.00004 0.00005 0.00005 0.00004\n",
            "  0.00005 0.00004 0.00011 0.00004 0.00004 0.00004]\n",
            " [0.00005 0.00006 0.00006 0.00006 0.00006 0.00005 0.00007 0.00005 0.00006\n",
            "  0.00007 0.00004 0.00004 0.00015 0.00006 0.00006]\n",
            " [0.00008 0.00007 0.00007 0.00007 0.00007 0.00006 0.00008 0.00007 0.00006\n",
            "  0.00008 0.00003 0.00004 0.00006 0.00017 0.00008]\n",
            " [0.00007 0.00007 0.00007 0.00007 0.00007 0.00006 0.00008 0.00007 0.00005\n",
            "  0.00007 0.00004 0.00004 0.00006 0.00008 0.00026]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#equal weighted portfolio construction: Annualized risk and\n",
        "#expected annualized portfolio return\n",
        "#trading days = 251\n",
        "PortfolioSize = Columns\n",
        "EqualWeightVector = np.ones((1,PortfolioSize))*(1.0/PortfolioSize)\n",
        "EqWgtPortfolioRisk = np.sqrt(np.matmul((np.matmul(EqualWeightVector,covReturns)), \\\n",
        "                     np.transpose(EqualWeightVector)))\n",
        "EqWgtAnnPortfolioRisk = EqWgtPortfolioRisk*np.sqrt(251)*100\n",
        "EqWgtPortfolioReturn = np.matmul(EqualWeightVector, np.transpose(meanReturns))\n",
        "EqWgtAnnPortfolioReturn = 251*EqWgtPortfolioReturn * 100\n",
        "\n",
        "print(\"Annualized Portfolio Risk :  %4.2f\" % EqWgtAnnPortfolioRisk, \"%\")\n",
        "print(\"\\nAnnualized Expected Portfolio Return:  %4.2f\" %  EqWgtAnnPortfolioReturn,\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUBPuT4-8VQe",
        "outputId": "a9ed205a-d1ab-4b35-f176-d02eec78d7f8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annualized Portfolio Risk :  13.68 %\n",
            "\n",
            "Annualized Expected Portfolio Return:  12.34 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-04fde1f55366>:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(\"Annualized Portfolio Risk :  %4.2f\" % EqWgtAnnPortfolioRisk, \"%\")\n",
            "<ipython-input-27-04fde1f55366>:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(\"\\nAnnualized Expected Portfolio Return:  %4.2f\" %  EqWgtAnnPortfolioReturn,\"%\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal weighted portfolio: Diversification Ratio\n",
        "EqWgtPortfolioAssetStdDev = np.sqrt(np.diagonal(covReturns))\n",
        "EqWgtPortfolioDivRatio = np.sum(np.multiply(EqWgtPortfolioAssetStdDev, EqualWeightVector)) \\\n",
        "                         / EqWgtPortfolioRisk\n",
        "print(\"\\n Equal Weighted Portfolio:Diversification Ratio  %4.2f\" % EqWgtPortfolioDivRatio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYWOZzUU8Ydt",
        "outputId": "931101bb-4162-4cb3-aac1-d918fd46a798"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Equal Weighted Portfolio:Diversification Ratio  1.53\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-699e7d1deab3>:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(\"\\n Equal Weighted Portfolio:Diversification Ratio  %4.2f\" % EqWgtPortfolioDivRatio)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Inverse volatility weighted portfolio construction: Annualized risk and\n",
        "#Expected annualized portfolio return\n",
        "#Trading days = 251\n",
        "InvVolWeightAssets_Risk = np.sqrt(np.diagonal(covReturns))\n",
        "InvVolWeightAssets_ReciprocalRisk = 1.0/InvVolWeightAssets_Risk\n",
        "InvVolWeightAssets_ReciprocalRisk_Sum = np.sum(InvVolWeightAssets_ReciprocalRisk)\n",
        "InvVolWeightAssets_Weights = InvVolWeightAssets_ReciprocalRisk / \\\n",
        "                             InvVolWeightAssets_ReciprocalRisk_Sum\n",
        "InvVolWeightPortfolio_Risk = np.sqrt(np.matmul((np.matmul(InvVolWeightAssets_Weights,\\\n",
        "                             covReturns)), np.transpose(InvVolWeightAssets_Weights)))\n",
        "\n",
        "InvVolWeightPortfolio_AnnRisk = np.sqrt(251)* InvVolWeightPortfolio_Risk *100\n",
        "InvVolWeightPortfolio_AnnReturn = 251* np.matmul(InvVolWeightAssets_Weights,\\\n",
        "                                  np.transpose(meanReturns)) *100\n",
        "\n",
        "print(\"Annualized Portfolio Risk: %4.2f\" % InvVolWeightPortfolio_AnnRisk,\"%\\n\")\n",
        "print(\"Annualized Expected Portfolio Return: %4.2f\" % InvVolWeightPortfolio_AnnReturn,\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNxK94Qc8da7",
        "outputId": "3f62a0e2-524c-47b6-db6f-d2a48d7a1d86"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annualized Portfolio Risk: 13.24 %\n",
            "\n",
            "Annualized Expected Portfolio Return: 12.13 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse volatility weighted portfolio: Diversification Ratio\n",
        "InvVolWeightAssets_Risk= np.sqrt(np.diagonal(covReturns))\n",
        "InvVolWeightPortfolioDivRatio = \\\n",
        "np.sum(np.multiply(InvVolWeightAssets_Risk, InvVolWeightAssets_Weights))\\\n",
        "/ InvVolWeightPortfolio_Risk\n",
        "print(\"\\n Inverse Volatility  Weighted Portfolio:Diversification Ratio %4.2f\" \\\n",
        "      % InvVolWeightPortfolioDivRatio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41L2q39G8iCb",
        "outputId": "eb86fce1-c947-4520-ac7c-9bc851024080"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Inverse Volatility  Weighted Portfolio:Diversification Ratio 1.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#identify the \"mini\" stock universe dataset\n",
        "StockFileName = '/content/DJIA_Apr112014_Apr112019.csv'\n",
        "Rows = 1259\n",
        "Columns = 29"
      ],
      "metadata": {
        "id": "tdQd-buN8ksg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function obtains maximal return portfolio using linear programming\n",
        "def MaximizeReturns(MeanReturns, PortfolioSize):\n",
        "\n",
        "    #dependencies\n",
        "    from scipy.optimize import linprog\n",
        "    import numpy as np\n",
        "\n",
        "    c = (np.multiply(-1, MeanReturns))\n",
        "    A = np.ones([PortfolioSize,1]).T\n",
        "    b=[1]\n",
        "    res = linprog(c, A_ub = A, b_ub = b, bounds = (0,1), method = 'simplex')\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "St0KCIa88psf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function obtains minimal risk portfolio\n",
        "from scipy import optimize\n",
        "\n",
        "def MinimizeRisk(CovarReturns, PortfolioSize):\n",
        "\n",
        "    def  f(x, CovarReturns):\n",
        "        func = np.matmul(np.matmul(x, CovarReturns), x.T)\n",
        "        return func\n",
        "\n",
        "    def constraintEq(x):\n",
        "        A=np.ones(x.shape)\n",
        "        b=1\n",
        "        constraintVal = np.matmul(A,x.T)-b\n",
        "        return constraintVal\n",
        "\n",
        "    xinit=np.repeat(0.1, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':constraintEq})\n",
        "    lb = 0\n",
        "    ub = 1\n",
        "    bnds = tuple([(lb,ub) for x in xinit])\n",
        "\n",
        "    opt = optimize.minimize (f, x0 = xinit, args = (CovarReturns),  bounds = bnds, \\\n",
        "                             constraints = cons, tol = 10**-3)\n",
        "\n",
        "    return opt"
      ],
      "metadata": {
        "id": "p9huBUm_9Dzw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function obtains Minimal risk and Maximum return portfolios\n",
        "def MinimizeRiskConstr(MeanReturns, CovarReturns, PortfolioSize, R):\n",
        "\n",
        "    def  f(x,CovarReturns):\n",
        "\n",
        "        func = np.matmul(np.matmul(x,CovarReturns ), x.T)\n",
        "        return func\n",
        "\n",
        "    def constraintEq(x):\n",
        "        AEq=np.ones(x.shape)\n",
        "        bEq=1\n",
        "        EqconstraintVal = np.matmul(AEq,x.T)-bEq\n",
        "        return EqconstraintVal\n",
        "\n",
        "    def constraintIneq(x, MeanReturns, R):\n",
        "        AIneq = np.array(MeanReturns)\n",
        "        bIneq = R\n",
        "        IneqconstraintVal = np.matmul(AIneq,x.T) - bIneq\n",
        "        return IneqconstraintVal\n",
        "\n",
        "\n",
        "    xinit=np.repeat(0.1, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':constraintEq},\n",
        "            {'type':'ineq', 'fun':constraintIneq, 'args':(MeanReturns,R) })\n",
        "    lb = 0\n",
        "    ub = 1\n",
        "    bnds = tuple([(lb,ub) for x in xinit])\n",
        "\n",
        "    opt = optimize.minimize (f, args = (CovarReturns), method ='trust-constr',  \\\n",
        "                        x0 = xinit,   bounds = bnds, constraints = cons, tol = 10**-3)\n",
        "\n",
        "    return  opt"
      ],
      "metadata": {
        "id": "SvxYMBJi9KYz"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function computes asset returns\n",
        "def StockReturnsComputing(StockPrice, Rows, Columns):\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "    StockReturn = np.zeros([Rows-1, Columns])\n",
        "    for j in range(Columns):\n",
        "        for i in range(Rows-1):\n",
        "            StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])* 100\n",
        "\n",
        "    return StockReturn"
      ],
      "metadata": {
        "id": "Bf0Lo2Fj9Qva"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain optimal portfolio sets that maximize return and minimize risk\n",
        "StockFileName = '/content/DJIA_Apr112014_Apr112019_kpf1.csv'\n",
        "\n",
        "Rows = 1259\n",
        "Columns = 15\n",
        "portfolioSize = Columns\n",
        "\n",
        "df = pd.read_csv(StockFileName,  nrows= Rows)\n",
        "\n",
        "assetLabels = df.columns[1:Columns+1].tolist()\n",
        "print(assetLabels)\n",
        "\n",
        "StockData = df.iloc[0:, 1:]\n",
        "\n",
        "arStockPrices = np.asarray(StockData)\n",
        "[Rows, Cols]=arStockPrices.shape\n",
        "arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
        "\n",
        "meanReturns = np.mean(arReturns, axis = 0)\n",
        "covReturns = np.cov(arReturns, rowvar=False)\n",
        "\n",
        "np.set_printoptions(precision=3, suppress = True)\n",
        "\n",
        "print('Mean returns of assets in k-portfolio 1\\n', meanReturns)\n",
        "print('Variance-Covariance matrix of returns\\n', covReturns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxTbw9so9UFK",
        "outputId": "b126f67a-7c02-4cac-999e-f70ea16868fd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'DIS', 'GS', 'HD', 'IBM', 'JPM', 'KO', 'MCD', 'MRK', 'UNH', 'WBA']\n",
            "Mean returns of assets in k-portfolio 1\n",
            " [ 0.09   0.029  0.1    0.039  0.081  0.04   0.033  0.085 -0.016  0.06\n",
            "  0.019  0.057  0.036  0.095 -0.002]\n",
            "Variance-Covariance matrix of returns\n",
            " [[2.375 0.672 0.962 1.042 0.999 0.68  0.954 0.726 0.709 0.825 0.306 0.458\n",
            "  0.534 0.774 0.697]\n",
            " [0.672 1.648 0.8   0.95  0.7   0.569 1.065 0.658 0.663 1.001 0.307 0.35\n",
            "  0.556 0.718 0.667]\n",
            " [0.962 0.8   2.288 1.31  0.89  0.716 1.066 0.747 0.777 0.977 0.381 0.472\n",
            "  0.578 0.745 0.679]\n",
            " [1.042 0.95  1.31  2.733 1.041 0.688 1.321 0.796 0.885 1.169 0.358 0.455\n",
            "  0.616 0.72  0.681]\n",
            " [0.999 0.7   0.89  1.041 1.789 0.713 0.927 0.724 0.817 0.909 0.362 0.477\n",
            "  0.647 0.656 0.707]\n",
            " [0.68  0.569 0.716 0.688 0.713 1.35  0.773 0.586 0.574 0.717 0.302 0.368\n",
            "  0.466 0.557 0.631]\n",
            " [0.954 1.065 1.066 1.321 0.927 0.773 2.114 0.795 0.803 1.554 0.303 0.467\n",
            "  0.705 0.82  0.819]\n",
            " [0.726 0.658 0.747 0.796 0.724 0.586 0.795 1.39  0.619 0.753 0.343 0.472\n",
            "  0.487 0.659 0.689]\n",
            " [0.709 0.663 0.777 0.885 0.817 0.574 0.803 0.619 1.632 0.767 0.372 0.391\n",
            "  0.576 0.564 0.534]\n",
            " [0.825 1.001 0.977 1.169 0.909 0.717 1.554 0.753 0.767 1.702 0.324 0.483\n",
            "  0.675 0.761 0.717]\n",
            " [0.306 0.307 0.381 0.358 0.362 0.302 0.303 0.343 0.372 0.324 0.806 0.36\n",
            "  0.384 0.31  0.355]\n",
            " [0.458 0.35  0.472 0.455 0.477 0.368 0.467 0.472 0.391 0.483 0.36  1.086\n",
            "  0.402 0.43  0.433]\n",
            " [0.534 0.556 0.578 0.616 0.647 0.466 0.705 0.487 0.576 0.675 0.384 0.402\n",
            "  1.504 0.615 0.64 ]\n",
            " [0.774 0.718 0.745 0.72  0.656 0.557 0.82  0.659 0.564 0.761 0.31  0.43\n",
            "  0.615 1.722 0.78 ]\n",
            " [0.697 0.667 0.679 0.681 0.707 0.631 0.819 0.689 0.534 0.717 0.355 0.433\n",
            "  0.64  0.78  2.554]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Maximal expected portfolio return computation for the k-portfolio\n",
        "result1 = MaximizeReturns(meanReturns, portfolioSize)\n",
        "maxReturnWeights = result1.x\n",
        "maxExpPortfolioReturn = np.matmul(meanReturns.T, maxReturnWeights)\n",
        "print(\"Maximal Expected Portfolio Return:   %7.4f\" % maxExpPortfolioReturn )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C1LFjmS9e0l",
        "outputId": "0fb39efd-df08-4bb6-b051-8a022ee85bfa"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximal Expected Portfolio Return:    0.0997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-a5e561a13d63>:11: DeprecationWarning: `method='simplex'` is deprecated and will be removed in SciPy 1.11.0. Please use one of the HiGHS solvers (e.g. `method='highs'`) in new code.\n",
            "  res = linprog(c, A_ub = A, b_ub = b, bounds = (0,1), method = 'simplex')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#expected portfolio return computation for the minimum risk k-portfolio\n",
        "result2 = MinimizeRisk(covReturns, portfolioSize)\n",
        "minRiskWeights = result2.x\n",
        "minRiskExpPortfolioReturn = np.matmul(meanReturns.T, minRiskWeights)\n",
        "print(\"Expected Return of Minimum Risk Portfolio:  %7.4f\" % minRiskExpPortfolioReturn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNcoFUJX9hVM",
        "outputId": "b561d2ff-1aad-4d7e-bc84-cf13301ed7ae"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected Return of Minimum Risk Portfolio:   0.0361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute efficient set for the maximum return and minimum risk portfolios\n",
        "increment = 0.001\n",
        "low = minRiskExpPortfolioReturn\n",
        "high = maxExpPortfolioReturn\n",
        "\n",
        "xOptimal =[]\n",
        "minRiskPoint = []\n",
        "expPortfolioReturnPoint =[]\n",
        "\n",
        "while (low < high):\n",
        "\n",
        "    result3 = MinimizeRiskConstr(meanReturns, covReturns, portfolioSize, low)\n",
        "    xOptimal.append(result3.x)\n",
        "    expPortfolioReturnPoint.append(low)\n",
        "    low = low+increment\n",
        "\n",
        "xOptimalArray = np.array(xOptimal)\n",
        "\n",
        "minRiskPoint = np.diagonal(np.matmul((np.matmul(xOptimalArray,covReturns)),\\\n",
        "                                     np.transpose(xOptimalArray)))\n",
        "riskPoint =   np.sqrt(minRiskPoint*251)\n",
        "\n",
        "retPoint = 251*np.array(expPortfolioReturnPoint)\n",
        "\n",
        "print(\"Size of the  efficient set:\", xOptimalArray.shape )\n",
        "print(\"Optimal weights of the efficient set portfolios: \\n\", xOptimalArray)\n",
        "print(\"Annualized Risk and Return of the efficient set portfolios: \\n\", \\\n",
        "                                                np.c_[riskPoint, retPoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGkrRtY49kAv",
        "outputId": "1b0c4f65-670b-4b34-8171-ed3a2ae64d30"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py:504: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
            "  self.H.update(delta_x, delta_g)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the  efficient set: (64, 15)\n",
            "Optimal weights of the efficient set portfolios: \n",
            " [[ 0.028  0.039  0.023  0.017  0.026  0.103  0.017  0.05   0.032  0.021\n",
            "   0.319  0.192  0.062  0.047  0.025]\n",
            " [ 0.028  0.039  0.023  0.017  0.026  0.108  0.017  0.051  0.032  0.022\n",
            "   0.311  0.192  0.063  0.047  0.025]\n",
            " [ 0.029  0.039  0.024  0.017  0.027  0.108  0.017  0.052  0.031  0.022\n",
            "   0.309  0.192  0.062  0.048  0.024]\n",
            " [ 0.03   0.039  0.025  0.017  0.027  0.107  0.017  0.053  0.03   0.022\n",
            "   0.306  0.192  0.062  0.049  0.024]\n",
            " [ 0.031  0.038  0.024  0.016  0.028  0.086  0.016  0.059  0.028  0.022\n",
            "   0.316  0.197  0.06   0.056  0.023]\n",
            " [ 0.033  0.039  0.027  0.017  0.029  0.103  0.017  0.06   0.028  0.023\n",
            "   0.294  0.185  0.064  0.056  0.023]\n",
            " [ 0.034  0.039  0.028  0.017  0.03   0.102  0.017  0.063  0.027  0.023\n",
            "   0.29   0.184  0.064  0.059  0.023]\n",
            " [ 0.035  0.038  0.03   0.017  0.031  0.101  0.017  0.066  0.026  0.024\n",
            "   0.285  0.183  0.064  0.062  0.022]\n",
            " [ 0.036  0.038  0.031  0.018  0.033  0.099  0.017  0.069  0.025  0.024\n",
            "   0.277  0.184  0.062  0.065  0.022]\n",
            " [ 0.039  0.034  0.034  0.017  0.036  0.058  0.018  0.069  0.023  0.026\n",
            "   0.298  0.205  0.052  0.071  0.021]\n",
            " [ 0.04   0.033  0.036  0.017  0.037  0.056  0.017  0.072  0.022  0.026\n",
            "   0.295  0.203  0.051  0.075  0.021]\n",
            " [ 0.041  0.032  0.037  0.017  0.038  0.055  0.017  0.075  0.02   0.026\n",
            "   0.291  0.202  0.05   0.079  0.02 ]\n",
            " [ 0.05   0.039  0.047  0.026  0.048  0.053  0.026  0.07   0.027  0.036\n",
            "   0.242  0.179  0.054  0.073  0.028]\n",
            " [ 0.052  0.038  0.048  0.026  0.049  0.051  0.026  0.072  0.026  0.037\n",
            "   0.24   0.179  0.053  0.076  0.028]\n",
            " [ 0.052  0.038  0.049  0.026  0.049  0.05   0.026  0.073  0.025  0.037\n",
            "   0.24   0.179  0.053  0.077  0.027]\n",
            " [ 0.049  0.027  0.047  0.016  0.046  0.044  0.016  0.082  0.015  0.028\n",
            "   0.276  0.202  0.044  0.092  0.016]\n",
            " [ 0.053  0.025  0.051  0.016  0.049  0.04   0.016  0.083  0.014  0.029\n",
            "   0.273  0.202  0.041  0.095  0.015]\n",
            " [ 0.056  0.024  0.055  0.016  0.052  0.036  0.015  0.084  0.012  0.03\n",
            "   0.268  0.202  0.039  0.097  0.014]\n",
            " [ 0.059  0.022  0.059  0.016  0.055  0.032  0.015  0.084  0.011  0.031\n",
            "   0.264  0.201  0.036  0.1    0.013]\n",
            " [ 0.063  0.021  0.064  0.015  0.059  0.028  0.015  0.085  0.01   0.032\n",
            "   0.259  0.201  0.034  0.102  0.012]\n",
            " [ 0.066  0.019  0.068  0.015  0.062  0.025  0.015  0.086  0.008  0.033\n",
            "   0.254  0.2    0.032  0.105  0.011]\n",
            " [ 0.069  0.018  0.071  0.015  0.064  0.022  0.015  0.087  0.007  0.033\n",
            "   0.25   0.2    0.03   0.107  0.011]\n",
            " [ 0.069  0.017  0.072  0.015  0.065  0.021  0.015  0.088  0.007  0.033\n",
            "   0.251  0.201  0.029  0.108  0.01 ]\n",
            " [ 0.068  0.016  0.076  0.01   0.064  0.025  0.01   0.103  0.007  0.024\n",
            "   0.237  0.201  0.028  0.121  0.009]\n",
            " [ 0.071  0.015  0.08   0.009  0.068  0.023  0.009  0.103  0.007  0.023\n",
            "   0.232  0.201  0.025  0.126  0.008]\n",
            " [ 0.066  0.015  0.083  0.01   0.072  0.021  0.01   0.111  0.007  0.025\n",
            "   0.219  0.198  0.024  0.132  0.009]\n",
            " [ 0.071  0.013  0.093  0.009  0.078  0.019  0.009  0.108  0.007  0.024\n",
            "   0.214  0.197  0.02   0.129  0.008]\n",
            " [ 0.067  0.012  0.079  0.009  0.069  0.016  0.009  0.125  0.006  0.025\n",
            "   0.207  0.197  0.022  0.153  0.007]\n",
            " [ 0.069  0.01   0.082  0.008  0.072  0.013  0.008  0.127  0.005  0.025\n",
            "   0.202  0.197  0.019  0.157  0.006]\n",
            " [ 0.069  0.01   0.083  0.007  0.073  0.012  0.007  0.128  0.004  0.024\n",
            "   0.202  0.198  0.018  0.159  0.005]\n",
            " [ 0.07   0.009  0.084  0.007  0.073  0.011  0.007  0.129  0.004  0.024\n",
            "   0.202  0.199  0.017  0.16   0.005]\n",
            " [ 0.066  0.013  0.086  0.008  0.072  0.029  0.007  0.148  0.006  0.017\n",
            "   0.144  0.191  0.029  0.177  0.006]\n",
            " [ 0.068  0.013  0.09   0.007  0.074  0.027  0.007  0.151  0.006  0.017\n",
            "   0.135  0.19   0.027  0.183  0.006]\n",
            " [ 0.065  0.012  0.09   0.007  0.073  0.025  0.007  0.161  0.006  0.017\n",
            "   0.123  0.194  0.025  0.189  0.006]\n",
            " [ 0.067  0.012  0.094  0.007  0.076  0.024  0.007  0.163  0.005  0.016\n",
            "   0.114  0.194  0.023  0.193  0.006]\n",
            " [ 0.068  0.011  0.098  0.007  0.078  0.022  0.007  0.166  0.005  0.016\n",
            "   0.105  0.193  0.021  0.199  0.006]\n",
            " [ 0.071  0.011  0.106  0.007  0.086  0.021  0.007  0.162  0.005  0.016\n",
            "   0.099  0.184  0.018  0.202  0.005]\n",
            " [ 0.077  0.008  0.11   0.005  0.088  0.011  0.005  0.164  0.004  0.011\n",
            "   0.107  0.191  0.01   0.204  0.005]\n",
            " [ 0.073  0.009  0.117  0.007  0.083  0.015  0.007  0.179  0.005  0.016\n",
            "   0.079  0.184  0.014  0.205  0.005]\n",
            " [ 0.074  0.009  0.121  0.007  0.085  0.015  0.007  0.183  0.005  0.017\n",
            "   0.067  0.181  0.014  0.209  0.005]\n",
            " [ 0.075  0.009  0.125  0.007  0.086  0.015  0.007  0.188  0.005  0.017\n",
            "   0.055  0.179  0.014  0.214  0.005]\n",
            " [ 0.075  0.009  0.129  0.007  0.088  0.014  0.007  0.191  0.005  0.017\n",
            "   0.046  0.177  0.014  0.217  0.005]\n",
            " [ 0.075  0.008  0.13   0.006  0.088  0.014  0.006  0.193  0.004  0.016\n",
            "   0.045  0.177  0.013  0.218  0.005]\n",
            " [ 0.078  0.008  0.138  0.006  0.084  0.013  0.006  0.201  0.005  0.016\n",
            "   0.021  0.178  0.013  0.227  0.005]\n",
            " [ 0.08   0.008  0.144  0.006  0.085  0.012  0.006  0.204  0.004  0.015\n",
            "   0.011  0.175  0.012  0.231  0.005]\n",
            " [ 0.082  0.008  0.15   0.006  0.085  0.012  0.006  0.207  0.004  0.015\n",
            "   0.001  0.173  0.011  0.235  0.005]\n",
            " [ 0.081  0.004  0.156  0.004  0.083  0.008  0.004  0.218  0.002  0.009\n",
            "   0.015  0.164  0.008  0.242  0.002]\n",
            " [ 0.086  0.003  0.159  0.004  0.079  0.006  0.003  0.223  0.002  0.008\n",
            "   0.014  0.15   0.007  0.253  0.002]\n",
            " [ 0.085  0.002  0.164  0.003  0.076  0.003  0.003  0.221  0.001  0.006\n",
            "   0.003  0.171  0.002  0.259  0.001]\n",
            " [ 0.086  0.002  0.165  0.002  0.076  0.002  0.002  0.222  0.001  0.005\n",
            "   0.003  0.172  0.002  0.26   0.001]\n",
            " [ 0.088  0.002  0.177  0.003  0.072  0.003  0.003  0.233  0.001  0.006\n",
            "   0.003  0.117  0.003  0.288  0.001]\n",
            " [ 0.091  0.002  0.186  0.003  0.07   0.003  0.003  0.235  0.001  0.006\n",
            "   0.003  0.093  0.003  0.301  0.001]\n",
            " [ 0.097  0.003  0.195  0.003  0.064  0.004  0.003  0.248  0.001  0.006\n",
            "   0.003  0.058  0.004  0.309  0.002]\n",
            " [ 0.109  0.003  0.207  0.003  0.059  0.004  0.003  0.242  0.001  0.006\n",
            "   0.003  0.038  0.004  0.317  0.002]\n",
            " [ 0.119  0.002  0.222  0.003  0.038  0.003  0.002  0.241  0.001  0.006\n",
            "   0.003  0.024  0.003  0.331  0.001]\n",
            " [ 0.112  0.002  0.24   0.002  0.038  0.003  0.002  0.236  0.001  0.005\n",
            "   0.003  0.007  0.003  0.344  0.001]\n",
            " [ 0.091  0.001  0.247  0.001  0.022  0.001  0.001  0.264  0.001  0.002\n",
            "   0.001  0.004  0.001  0.361  0.001]\n",
            " [ 0.096  0.001  0.301  0.001  0.018  0.002  0.001  0.174  0.001  0.003\n",
            "   0.001  0.004  0.002  0.394  0.001]\n",
            " [ 0.098  0.     0.315  0.     0.006  0.001  0.     0.168  0.     0.001\n",
            "   0.     0.001  0.001  0.407  0.   ]\n",
            " [ 0.088  0.001  0.382  0.001  0.012  0.001  0.001  0.067  0.     0.001\n",
            "   0.001  0.003  0.001  0.44   0.001]\n",
            " [ 0.062  0.001  0.432  0.001  0.006  0.001  0.001  0.031  0.     0.001\n",
            "   0.001  0.002  0.001  0.46   0.   ]\n",
            " [ 0.048  0.     0.461  0.     0.002  0.     0.     0.027 -0.    -0.\n",
            "   0.    -0.     0.     0.461  0.   ]\n",
            " [ 0.045 -0.     0.467 -0.     0.001 -0.    -0.     0.026 -0.001 -0.\n",
            "  -0.    -0.001 -0.     0.464 -0.   ]\n",
            " [ 0.006 -0.     0.642  0.     0.     0.    -0.    -0.    -0.    -0.\n",
            "  -0.    -0.001 -0.     0.355 -0.   ]]\n",
            "Annualized Risk and Return of the efficient set portfolios: \n",
            " [[11.571  9.049]\n",
            " [11.585  9.3  ]\n",
            " [11.592  9.551]\n",
            " [11.599  9.802]\n",
            " [11.591 10.053]\n",
            " [11.641 10.304]\n",
            " [11.656 10.555]\n",
            " [11.675 10.806]\n",
            " [11.701 11.057]\n",
            " [11.706 11.308]\n",
            " [11.725 11.559]\n",
            " [11.743 11.81 ]\n",
            " [11.991 12.061]\n",
            " [12.013 12.312]\n",
            " [12.023 12.563]\n",
            " [11.86  12.814]\n",
            " [11.905 13.065]\n",
            " [11.953 13.316]\n",
            " [12.004 13.567]\n",
            " [12.056 13.818]\n",
            " [12.11  14.069]\n",
            " [12.161 14.32 ]\n",
            " [12.174 14.571]\n",
            " [12.201 14.822]\n",
            " [12.258 15.073]\n",
            " [12.339 15.324]\n",
            " [12.413 15.575]\n",
            " [12.427 15.826]\n",
            " [12.487 16.077]\n",
            " [12.509 16.328]\n",
            " [12.522 16.579]\n",
            " [12.75  16.83 ]\n",
            " [12.837 17.081]\n",
            " [12.913 17.332]\n",
            " [13.003 17.583]\n",
            " [13.096 17.834]\n",
            " [13.206 18.085]\n",
            " [13.239 18.336]\n",
            " [13.41  18.587]\n",
            " [13.525 18.838]\n",
            " [13.643 19.089]\n",
            " [13.741 19.34 ]\n",
            " [13.765 19.591]\n",
            " [13.979 19.842]\n",
            " [14.1   20.093]\n",
            " [14.223 20.344]\n",
            " [14.229 20.595]\n",
            " [14.354 20.846]\n",
            " [14.412 21.097]\n",
            " [14.439 21.348]\n",
            " [14.775 21.599]\n",
            " [14.969 21.85 ]\n",
            " [15.212 22.101]\n",
            " [15.426 22.352]\n",
            " [15.647 22.603]\n",
            " [15.866 22.854]\n",
            " [15.982 23.105]\n",
            " [16.396 23.356]\n",
            " [16.593 23.607]\n",
            " [17.243 23.858]\n",
            " [17.766 24.109]\n",
            " [18.016 24.36 ]\n",
            " [18.097 24.611]\n",
            " [19.449 24.862]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph Efficient Frontier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "NoPoints = riskPoint.size\n",
        "\n",
        "colours = \"blue\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for k-portfolio 1 of Dow stocks')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(riskPoint, retPoint, s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "frRUKIrq9qAe",
        "outputId": "c3fad68d-26a1-47ea-b524-028563bcc156"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to undertake Sharpe Ratio maximization subject to\n",
        "#basic constraints of the portfolio\n",
        "\n",
        "def MaximizeSharpeRatioOptmzn(MeanReturns, CovarReturns, RiskFreeRate, PortfolioSize):\n",
        "\n",
        "    def  f(x, MeanReturns, CovarReturns, RiskFreeRate, PortfolioSize):\n",
        "        funcDenomr = np.sqrt(np.matmul(np.matmul(x, CovarReturns), x.T) )\n",
        "        funcNumer = np.matmul(np.array(MeanReturns),x.T)-RiskFreeRate\n",
        "        func = -(funcNumer / funcDenomr)\n",
        "        return func\n",
        "\n",
        "    def constraintEq(x):\n",
        "        A=np.ones(x.shape)\n",
        "        b=1\n",
        "        constraintVal = np.matmul(A,x.T)-b\n",
        "        return constraintVal\n",
        "\n",
        "    xinit=np.repeat(0.33, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':constraintEq})\n",
        "    lb = 0\n",
        "    ub = 1\n",
        "    bnds = tuple([(lb,ub) for x in xinit])\n",
        "\n",
        "    opt = optimize.minimize (f, x0 = xinit, args = (MeanReturns, CovarReturns,\\\n",
        "                             RiskFreeRate, PortfolioSize), method = 'SLSQP',  \\\n",
        "                             bounds = bnds, constraints = cons, tol = 10**-3)\n",
        "\n",
        "    return opt"
      ],
      "metadata": {
        "id": "VTyRrVyf9tku"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function computes asset returns\n",
        "def StockReturnsComputing(StockPrice, Rows, Columns):\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "    StockReturn = np.zeros([Rows-1, Columns])\n",
        "    for j in range(Columns):        # j: Assets\n",
        "        for i in range(Rows-1):     # i: Daily Prices\n",
        "            StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])* 100\n",
        "\n",
        "    return StockReturn"
      ],
      "metadata": {
        "id": "DxbcbiKi-PDx"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#obtain mean and variance-covariance matrix of returns for k-portfolio 1\n",
        "\n",
        "StockFileName = '/content/DJIA_Apr112014_Apr112019_kpf1.csv'\n",
        "Rows = 1259\n",
        "Columns = 15\n",
        "\n",
        "df = pd.read_csv(StockFileName,  nrows= Rows)\n",
        "\n",
        "assetLabels = df.columns[1:Columns+1].tolist()\n",
        "print('Asset labels of k-portfolio 1: \\n', assetLabels)\n",
        "\n",
        "StockData = df.iloc[0:, 1:]\n",
        "\n",
        "arStockPrices = np.asarray(StockData)\n",
        "[Rows, Cols]=arStockPrices.shape\n",
        "arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
        "\n",
        "np.set_printoptions(precision=3, suppress = True)\n",
        "\n",
        "meanReturns = np.mean(arReturns, axis = 0)\n",
        "covReturns = np.cov(arReturns, rowvar=False)\n",
        "print('\\nMean Returns:\\n', meanReturns)\n",
        "print('\\nVariance-Covariance Matrix of Returns:\\n', covReturns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ9-MHEh-ZLa",
        "outputId": "284eb035-6a12-4564-ea6a-f315558a47af"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asset labels of k-portfolio 1: \n",
            " ['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'DIS', 'GS', 'HD', 'IBM', 'JPM', 'KO', 'MCD', 'MRK', 'UNH', 'WBA']\n",
            "\n",
            "Mean Returns:\n",
            " [ 0.09   0.029  0.1    0.039  0.081  0.04   0.033  0.085 -0.016  0.06\n",
            "  0.019  0.057  0.036  0.095 -0.002]\n",
            "\n",
            "Variance-Covariance Matrix of Returns:\n",
            " [[2.375 0.672 0.962 1.042 0.999 0.68  0.954 0.726 0.709 0.825 0.306 0.458\n",
            "  0.534 0.774 0.697]\n",
            " [0.672 1.648 0.8   0.95  0.7   0.569 1.065 0.658 0.663 1.001 0.307 0.35\n",
            "  0.556 0.718 0.667]\n",
            " [0.962 0.8   2.288 1.31  0.89  0.716 1.066 0.747 0.777 0.977 0.381 0.472\n",
            "  0.578 0.745 0.679]\n",
            " [1.042 0.95  1.31  2.733 1.041 0.688 1.321 0.796 0.885 1.169 0.358 0.455\n",
            "  0.616 0.72  0.681]\n",
            " [0.999 0.7   0.89  1.041 1.789 0.713 0.927 0.724 0.817 0.909 0.362 0.477\n",
            "  0.647 0.656 0.707]\n",
            " [0.68  0.569 0.716 0.688 0.713 1.35  0.773 0.586 0.574 0.717 0.302 0.368\n",
            "  0.466 0.557 0.631]\n",
            " [0.954 1.065 1.066 1.321 0.927 0.773 2.114 0.795 0.803 1.554 0.303 0.467\n",
            "  0.705 0.82  0.819]\n",
            " [0.726 0.658 0.747 0.796 0.724 0.586 0.795 1.39  0.619 0.753 0.343 0.472\n",
            "  0.487 0.659 0.689]\n",
            " [0.709 0.663 0.777 0.885 0.817 0.574 0.803 0.619 1.632 0.767 0.372 0.391\n",
            "  0.576 0.564 0.534]\n",
            " [0.825 1.001 0.977 1.169 0.909 0.717 1.554 0.753 0.767 1.702 0.324 0.483\n",
            "  0.675 0.761 0.717]\n",
            " [0.306 0.307 0.381 0.358 0.362 0.302 0.303 0.343 0.372 0.324 0.806 0.36\n",
            "  0.384 0.31  0.355]\n",
            " [0.458 0.35  0.472 0.455 0.477 0.368 0.467 0.472 0.391 0.483 0.36  1.086\n",
            "  0.402 0.43  0.433]\n",
            " [0.534 0.556 0.578 0.616 0.647 0.466 0.705 0.487 0.576 0.675 0.384 0.402\n",
            "  1.504 0.615 0.64 ]\n",
            " [0.774 0.718 0.745 0.72  0.656 0.557 0.82  0.659 0.564 0.761 0.31  0.43\n",
            "  0.615 1.722 0.78 ]\n",
            " [0.697 0.667 0.679 0.681 0.707 0.631 0.819 0.689 0.534 0.717 0.355 0.433\n",
            "  0.64  0.78  2.554]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#obtain maximal Sharpe Ratio for k-portfolio 1 of Dow stocks\n",
        "\n",
        "portfolioSize = Columns\n",
        "\n",
        "Rf=3\n",
        "annRiskFreeRate = Rf/100\n",
        "\n",
        "r0 = (np.power((1 + annRiskFreeRate),  (1.0 / 360.0)) - 1.0) * 100\n",
        "print('\\nRisk free rate (daily %): ', end=\"\")\n",
        "print (\"{0:.3f}\".format(r0))\n",
        "\n",
        "xOptimal =[]\n",
        "minRiskPoint = []\n",
        "expPortfolioReturnPoint =[]\n",
        "maxSharpeRatio = 0\n",
        "\n",
        "result = MaximizeSharpeRatioOptmzn(meanReturns, covReturns, r0, portfolioSize)\n",
        "xOptimal.append(result.x)\n",
        "\n",
        "\n",
        "xOptimalArray = np.array(xOptimal)\n",
        "Risk = np.matmul((np.matmul(xOptimalArray,covReturns)), np.transpose(xOptimalArray))\n",
        "expReturn = np.matmul(np.array(meanReturns),xOptimalArray.T)\n",
        "annRisk =   np.sqrt(Risk*251)\n",
        "annRet = 251*np.array(expReturn)\n",
        "maxSharpeRatio = (annRet-Rf)/annRisk\n",
        "\n",
        "np.set_printoptions(precision=3, suppress = True)\n",
        "\n",
        "print('Maximal Sharpe Ratio: ', maxSharpeRatio, '\\nAnnualized Risk (%):  ', \\\n",
        "      annRisk, '\\nAnnualized Expected Portfolio Return(%):  ', annRet)\n",
        "print('\\nOptimal weights (%):\\n',  xOptimalArray.T*100 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI-fNaB6-jK4",
        "outputId": "3cc07718-5675-4317-b36d-7129cf0cae59"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Risk free rate (daily %): 0.008\n",
            "Maximal Sharpe Ratio:  [[1.26]] \n",
            "Annualized Risk (%):   [[14.749]] \n",
            "Annualized Expected Portfolio Return(%):   [21.584]\n",
            "\n",
            "Optimal weights (%):\n",
            " [[13.694]\n",
            " [ 0.   ]\n",
            " [17.744]\n",
            " [ 0.   ]\n",
            " [12.151]\n",
            " [ 0.   ]\n",
            " [ 0.   ]\n",
            " [19.058]\n",
            " [ 0.   ]\n",
            " [ 1.151]\n",
            " [ 0.   ]\n",
            " [13.654]\n",
            " [ 0.   ]\n",
            " [22.547]\n",
            " [ 0.   ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function computes asset returns\n",
        "def StockReturnsComputing(StockPrice, Rows, Columns):\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "    StockReturn = np.zeros([Rows-1, Columns])\n",
        "    for j in range(Columns):\n",
        "        for i in range(Rows-1):\n",
        "            StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])*100\n",
        "\n",
        "    return StockReturn"
      ],
      "metadata": {
        "id": "a43H23aV-vFg"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute stock returns for k-portfolio 1 and market returns to compute asset betas\n",
        "\n",
        "stockFileName = '/content/DJIAkpf1Apr2016to20193YBeta.csv'\n",
        "marketFileName = '/content/DJIAMarketDataApr2016to20193YBeta.csv'\n",
        "stockRows = 756\n",
        "stockColumns = 15\n",
        "marketRows = 756\n",
        "marketColumns = 7\n",
        "\n",
        "dfStock = pd.read_csv(stockFileName,  nrows= stockRows)\n",
        "dfMarket = pd.read_csv(marketFileName, nrows = marketRows)\n",
        "stockData = dfStock.iloc[0:, 1:]\n",
        "marketData = dfMarket.iloc[0:, [4]]\n",
        "\n",
        "assetLabels = dfStock.columns[1:stockColumns+1].tolist()\n",
        "print('Asset labels of k-portfolio 1: \\n', assetLabels)\n",
        "\n",
        "arStockPrices = np.asarray(stockData)\n",
        "[sRows, sCols]=arStockPrices.shape\n",
        "arStockReturns = StockReturnsComputing(arStockPrices, sRows, sCols)\n",
        "\n",
        "arMarketPrices = np.asarray(marketData)\n",
        "[mRows, mCols]=arMarketPrices.shape\n",
        "arMarketReturns = StockReturnsComputing(arMarketPrices, mRows, mCols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAFicUZN_jmH",
        "outputId": "e7e55a12-673a-4dc6-a69f-1aeefd7b5ea4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asset labels of k-portfolio 1: \n",
            " ['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'DIS', 'GS', 'HD', 'IBM', 'JPM', 'KO', 'MCD', 'MRK', 'UNH', 'WBA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute betas of the assets in k-portfolio 1\n",
        "beta= []\n",
        "Var = np.var(arMarketReturns, ddof =1)\n",
        "for i in range(stockColumns):\n",
        "    CovarMat = np.cov(arMarketReturns[:,0], arStockReturns[:, i ])\n",
        "    Covar  = CovarMat[1,0]\n",
        "    beta.append(Covar/Var)\n",
        "\n",
        "print('Asset Betas:\\n')\n",
        "for data in beta:\n",
        "    print('{:9.3f}'.format(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_V46bt9_3Zd",
        "outputId": "84922c6d-40a3-4028-d739-919b64203e35"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asset Betas:\n",
            "\n",
            "    1.134\n",
            "    1.087\n",
            "    1.392\n",
            "    1.527\n",
            "    1.154\n",
            "    0.767\n",
            "    1.317\n",
            "    0.937\n",
            "    0.976\n",
            "    1.115\n",
            "    0.460\n",
            "    0.554\n",
            "    0.735\n",
            "    0.950\n",
            "    0.850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#obtain mean returns and variance-covariance matrix of returns of k-portfolio 1\n",
        "#historical dataset: DJIA Index April 2014 to April 2019\n",
        "\n",
        "StockFileName = 'DJIA_Apr112014_Apr112019_kpf1.csv'\n",
        "Rows = 1259\n",
        "Columns = 15\n",
        "\n",
        "df = pd.read_csv(StockFileName,  nrows= Rows)\n",
        "\n",
        "assetLabels = df.columns[1:Columns+1].tolist()\n",
        "print('Asset labels for k-portfolio 1: \\n', assetLabels)\n",
        "\n",
        "stockData = df.iloc[0:, 1:]\n",
        "\n",
        "arStockPrices = np.asarray(stockData)\n",
        "[Rows, Cols]=arStockPrices.shape\n",
        "arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
        "\n",
        "np.set_printoptions(precision=3, suppress = True)\n",
        "\n",
        "meanReturns = np.mean(arReturns, axis = 0)\n",
        "covReturns = np.cov(arReturns, rowvar=False)\n",
        "print('\\nMean Returns:\\n', meanReturns)\n",
        "print('\\nVariance-Covariance Matrix of Returns:\\n', covReturns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4nvvMdgAHF-",
        "outputId": "b7045247-6fb5-46df-cfcf-ac76e52f522d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asset labels for k-portfolio 1: \n",
            " ['AAPL', 'AXP', 'BA', 'CAT', 'CSCO', 'DIS', 'GS', 'HD', 'IBM', 'JPM', 'KO', 'MCD', 'MRK', 'UNH', 'WBA']\n",
            "\n",
            "Mean Returns:\n",
            " [ 0.09   0.029  0.1    0.039  0.081  0.04   0.033  0.085 -0.016  0.06\n",
            "  0.019  0.057  0.036  0.095 -0.002]\n",
            "\n",
            "Variance-Covariance Matrix of Returns:\n",
            " [[2.375 0.672 0.962 1.042 0.999 0.68  0.954 0.726 0.709 0.825 0.306 0.458\n",
            "  0.534 0.774 0.697]\n",
            " [0.672 1.648 0.8   0.95  0.7   0.569 1.065 0.658 0.663 1.001 0.307 0.35\n",
            "  0.556 0.718 0.667]\n",
            " [0.962 0.8   2.288 1.31  0.89  0.716 1.066 0.747 0.777 0.977 0.381 0.472\n",
            "  0.578 0.745 0.679]\n",
            " [1.042 0.95  1.31  2.733 1.041 0.688 1.321 0.796 0.885 1.169 0.358 0.455\n",
            "  0.616 0.72  0.681]\n",
            " [0.999 0.7   0.89  1.041 1.789 0.713 0.927 0.724 0.817 0.909 0.362 0.477\n",
            "  0.647 0.656 0.707]\n",
            " [0.68  0.569 0.716 0.688 0.713 1.35  0.773 0.586 0.574 0.717 0.302 0.368\n",
            "  0.466 0.557 0.631]\n",
            " [0.954 1.065 1.066 1.321 0.927 0.773 2.114 0.795 0.803 1.554 0.303 0.467\n",
            "  0.705 0.82  0.819]\n",
            " [0.726 0.658 0.747 0.796 0.724 0.586 0.795 1.39  0.619 0.753 0.343 0.472\n",
            "  0.487 0.659 0.689]\n",
            " [0.709 0.663 0.777 0.885 0.817 0.574 0.803 0.619 1.632 0.767 0.372 0.391\n",
            "  0.576 0.564 0.534]\n",
            " [0.825 1.001 0.977 1.169 0.909 0.717 1.554 0.753 0.767 1.702 0.324 0.483\n",
            "  0.675 0.761 0.717]\n",
            " [0.306 0.307 0.381 0.358 0.362 0.302 0.303 0.343 0.372 0.324 0.806 0.36\n",
            "  0.384 0.31  0.355]\n",
            " [0.458 0.35  0.472 0.455 0.477 0.368 0.467 0.472 0.391 0.483 0.36  1.086\n",
            "  0.402 0.43  0.433]\n",
            " [0.534 0.556 0.578 0.616 0.647 0.466 0.705 0.487 0.576 0.675 0.384 0.402\n",
            "  1.504 0.615 0.64 ]\n",
            " [0.774 0.718 0.745 0.72  0.656 0.557 0.82  0.659 0.564 0.761 0.31  0.43\n",
            "  0.615 1.722 0.78 ]\n",
            " [0.697 0.667 0.679 0.681 0.707 0.631 0.819 0.689 0.534 0.717 0.355 0.433\n",
            "  0.64  0.78  2.554]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to handle bi-criterion portfolio optimization with constraints\n",
        "\n",
        "def BiCriterionFunctionOptmzn(MeanReturns, CovarReturns, RiskAversParam, PortfolioSize):\n",
        "\n",
        "    def  f(x, MeanReturns, CovarReturns, RiskAversParam, PortfolioSize):\n",
        "        PortfolioVariance = np.matmul(np.matmul(x, CovarReturns), x.T)\n",
        "        PortfolioExpReturn = np.matmul(np.array(MeanReturns),x.T)\n",
        "        func = RiskAversParam * PortfolioVariance - (1-RiskAversParam)*PortfolioExpReturn\n",
        "        return func\n",
        "\n",
        "    def ConstraintEq(x):\n",
        "        A=np.ones(x.shape)\n",
        "        b=1\n",
        "        constraintVal = np.matmul(A,x.T)-b\n",
        "        return constraintVal\n",
        "\n",
        "    def ConstraintIneqUpBounds(x):\n",
        "        A= [[0,0,0,0,0, 1,0,1,1,0, 1,1,1,1,1], [1,1,1,1,1,0,1,0,0,1,0,0,0,0,0]]\n",
        "        bUpBounds =np.array([0.6,0.4]).T\n",
        "        constraintValUpBounds = bUpBounds-np.matmul(A,x.T)\n",
        "        return constraintValUpBounds\n",
        "\n",
        "    def ConstraintIneqLowBounds(x):\n",
        "        A= [[0,0,0,0,0,1,0,1,1,0, 1,1,1,1,1], [1,1,1,1,1,0,1,0,0,1,0,0,0,0,0]]\n",
        "        bLowBounds =np.array([0.01, 0.01]).T\n",
        "        constraintValLowBounds = np.matmul(A,x.T)-bLowBounds\n",
        "        return constraintValLowBounds\n",
        "\n",
        "    xinit=np.repeat(0.01, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':ConstraintEq}, \\\n",
        "            {'type':'ineq', 'fun': ConstraintIneqUpBounds},\\\n",
        "            {'type':'ineq', 'fun': ConstraintIneqLowBounds})\n",
        "    bnds = [(0,0.1),(0,0.1), (0,0.1), (0,0.1), (0,0.1), (0,1), (0,0.1), (0,1),\\\n",
        "            (0,1), (0,0.1), (0,1),  (0,1),(0,1),(0,1),(0,1)]\n",
        "\n",
        "    opt = optimize.minimize (f, x0 = xinit, args = ( MeanReturns, CovarReturns,\\\n",
        "                                                    RiskAversParam, PortfolioSize), \\\n",
        "                             method = 'SLSQP',  bounds = bnds, constraints = cons, \\\n",
        "                             tol = 10**-3)\n",
        "    print(opt)\n",
        "    return opt"
      ],
      "metadata": {
        "id": "XCgXntwhD4z0"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#obtain optimal portfolios for the constrained portfolio optimization model\n",
        "#Maximize returns and Minimize risk with fully invested, bound and class constraints\n",
        "\n",
        "portfolioSize = Columns\n",
        "\n",
        "xOptimal =[]\n",
        "minRiskPoint = []\n",
        "expPortfolioReturnPoint =[]\n",
        "\n",
        "for points in range(0,60):\n",
        "    riskAversParam = points/60.0\n",
        "    result = BiCriterionFunctionOptmzn(meanReturns, covReturns, riskAversParam, \\\n",
        "                                       portfolioSize)\n",
        "    xOptimal.append(result.x)\n",
        "\n",
        "xOptimalArray = np.array(xOptimal)\n",
        "minRiskPoint = np.diagonal(np.matmul((np.matmul(xOptimalArray,covReturns)),\\\n",
        "                                     np.transpose(xOptimalArray)))\n",
        "riskPoint =   np.sqrt(minRiskPoint*251)\n",
        "expPortfolioReturnPoint= np.matmul(xOptimalArray, meanReturns )\n",
        "retPoint = 251*np.array(expPortfolioReturnPoint)\n",
        "\n",
        "np.set_printoptions(precision=3, suppress = True)\n",
        "\n",
        "print(\"Optimal weights of the efficient set portfolios\\n:\", xOptimalArray)\n",
        "print(\"\\nAnnualized Risk and Return of the efficient set portfolios:\\n\",\\\n",
        "      np.c_[riskPoint, retPoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOTMeEXVECK8",
        "outputId": "bed10978-6147-4a41-aaf9-f31b3e672dbb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: -0.0871814657741943\n",
            "       x: [ 1.000e-01  6.319e-18 ...  3.366e-01  7.196e-17]\n",
            "     nit: 6\n",
            "     jac: [-9.028e-02 -2.910e-02 ... -9.548e-02  1.685e-03]\n",
            "    nfev: 96\n",
            "    njev: 6\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: -0.06831630616273264\n",
            "       x: [ 1.000e-01  1.688e-17 ...  2.744e-01  0.000e+00]\n",
            "     nit: 5\n",
            "     jac: [-5.751e-02 -5.364e-03 ... -6.197e-02  2.474e-02]\n",
            "    nfev: 80\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: -0.0522821794930713\n",
            "       x: [ 1.000e-01  7.546e-17 ...  2.548e-01  1.654e-17]\n",
            "     nit: 5\n",
            "     jac: [-2.532e-02  1.770e-02 ... -3.029e-02  4.718e-02]\n",
            "    nfev: 80\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: -0.036810831036578735\n",
            "       x: [ 1.000e-01  0.000e+00 ...  2.358e-01  0.000e+00]\n",
            "     nit: 5\n",
            "     jac: [ 6.193e-03  4.005e-02 ... -4.543e-04  6.895e-02]\n",
            "    nfev: 80\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: -0.021763116685072033\n",
            "       x: [ 1.000e-01  6.213e-03 ...  2.025e-01  4.228e-18]\n",
            "     nit: 5\n",
            "     jac: [ 3.508e-02  6.077e-02 ...  2.402e-02  8.852e-02]\n",
            "    nfev: 80\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: -0.007955088253568186\n",
            "       x: [ 1.000e-01  1.845e-02 ...  1.731e-01  0.000e+00]\n",
            "     nit: 5\n",
            "     jac: [ 6.256e-02  8.133e-02 ...  4.582e-02  1.070e-01]\n",
            "    nfev: 80\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.004936308105846832\n",
            "       x: [ 1.000e-01  2.984e-02 ...  1.467e-01  2.125e-17]\n",
            "     nit: 5\n",
            "     jac: [ 8.890e-02  1.014e-01 ...  6.536e-02  1.245e-01]\n",
            "    nfev: 80\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.017207174497400834\n",
            "       x: [ 1.000e-01  4.054e-02 ...  1.235e-01  2.179e-17]\n",
            "     nit: 5\n",
            "     jac: [ 1.143e-01  1.210e-01 ...  8.310e-02  1.412e-01]\n",
            "    nfev: 80\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.029081173455873847\n",
            "       x: [ 1.000e-01  4.939e-02 ...  1.056e-01  1.495e-17]\n",
            "     nit: 5\n",
            "     jac: [ 1.394e-01  1.407e-01 ...  1.005e-01  1.577e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.04067066213718418\n",
            "       x: [ 9.515e-02  6.037e-02 ...  8.970e-02  7.156e-18]\n",
            "     nit: 5\n",
            "     jac: [ 1.616e-01  1.612e-01 ...  1.169e-01  1.739e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.05203730676766603\n",
            "       x: [ 8.760e-02  7.187e-02 ...  7.739e-02  5.529e-18]\n",
            "     nit: 5\n",
            "     jac: [ 1.818e-01  1.831e-01 ...  1.336e-01  1.903e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.06319518206559506\n",
            "       x: [ 8.431e-02  8.291e-02 ...  6.757e-02  0.000e+00]\n",
            "     nit: 5\n",
            "     jac: [ 2.038e-01  2.060e-01 ...  1.509e-01  2.072e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.07418715707185704\n",
            "       x: [ 8.173e-02  9.170e-02 ...  5.964e-02  0.000e+00]\n",
            "     nit: 5\n",
            "     jac: [ 2.260e-01  2.288e-01 ...  1.682e-01  2.241e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.08504967077544937\n",
            "       x: [ 7.977e-02  9.903e-02 ...  5.314e-02  6.505e-18]\n",
            "     nit: 5\n",
            "     jac: [ 2.484e-01  2.516e-01 ...  1.857e-01  2.411e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.09581326147923822\n",
            "       x: [ 7.995e-02  1.000e-01 ...  4.811e-02  2.168e-19]\n",
            "     nit: 5\n",
            "     jac: [ 2.729e-01  2.725e-01 ...  2.037e-01  2.584e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.1065146165964698\n",
            "       x: [ 8.048e-02  1.000e-01 ...  4.377e-02  2.261e-17]\n",
            "     nit: 5\n",
            "     jac: [ 2.977e-01  2.930e-01 ...  2.218e-01  2.757e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.11716566087486538\n",
            "       x: [ 8.104e-02  1.000e-01 ...  3.989e-02  0.000e+00]\n",
            "     nit: 5\n",
            "     jac: [ 3.225e-01  3.135e-01 ...  2.397e-01  2.929e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.12776367839057795\n",
            "       x: [ 8.121e-02  1.000e-01 ...  3.630e-02  2.168e-19]\n",
            "     nit: 5\n",
            "     jac: [ 3.466e-01  3.336e-01 ...  2.572e-01  3.097e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.13830950495114958\n",
            "       x: [ 8.062e-02  1.000e-01 ...  3.316e-02  0.000e+00]\n",
            "     nit: 5\n",
            "     jac: [ 3.695e-01  3.536e-01 ...  2.742e-01  3.262e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.1488290622885579\n",
            "       x: [ 8.008e-02  1.000e-01 ...  3.072e-02  0.000e+00]\n",
            "     nit: 5\n",
            "     jac: [ 3.926e-01  3.739e-01 ...  2.918e-01  3.428e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.1593244231554052\n",
            "       x: [ 7.962e-02  1.000e-01 ...  2.878e-02  2.003e-17]\n",
            "     nit: 5\n",
            "     jac: [ 4.158e-01  3.944e-01 ...  3.096e-01  3.596e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.16979956148042433\n",
            "       x: [ 7.919e-02  1.000e-01 ...  2.717e-02  3.786e-18]\n",
            "     nit: 5\n",
            "     jac: [ 4.391e-01  4.150e-01 ...  3.277e-01  3.765e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.18025670567181493\n",
            "       x: [ 7.915e-02  1.000e-01 ...  2.583e-02  0.000e+00]\n",
            "     nit: 5\n",
            "     jac: [ 4.628e-01  4.356e-01 ...  3.459e-01  3.935e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.19069853041851875\n",
            "       x: [ 7.915e-02  1.000e-01 ...  2.469e-02  0.000e+00]\n",
            "     nit: 4\n",
            "     jac: [ 4.991e-01  4.653e-01 ...  3.760e-01  4.211e-01]\n",
            "    nfev: 66\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.2011276828837929\n",
            "       x: [ 7.917e-02  1.000e-01 ...  2.370e-02  1.599e-18]\n",
            "     nit: 4\n",
            "     jac: [ 5.219e-01  4.851e-01 ...  3.924e-01  4.374e-01]\n",
            "    nfev: 66\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.21493135110023012\n",
            "       x: [ 8.192e-02  1.000e-01 ...  2.828e-02  1.000e-10]\n",
            "     nit: 3\n",
            "     jac: [ 5.658e-01  5.165e-01 ...  4.291e-01  4.674e-01]\n",
            "    nfev: 60\n",
            "    njev: 3\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.22195565868675166\n",
            "       x: [ 7.933e-02  1.000e-01 ...  2.201e-02  2.060e-17]\n",
            "     nit: 4\n",
            "     jac: [ 5.675e-01  5.248e-01 ...  4.256e-01  4.700e-01]\n",
            "    nfev: 66\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.23235735428484952\n",
            "       x: [ 7.949e-02  1.000e-01 ...  2.117e-02  2.846e-17]\n",
            "     nit: 4\n",
            "     jac: [ 5.903e-01  5.449e-01 ...  4.426e-01  4.863e-01]\n",
            "    nfev: 66\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.24275207284039924\n",
            "       x: [ 7.968e-02  1.000e-01 ...  2.023e-02  6.830e-18]\n",
            "     nit: 4\n",
            "     jac: [ 6.130e-01  5.650e-01 ...  4.598e-01  5.027e-01]\n",
            "    nfev: 66\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.2536184003386137\n",
            "       x: [ 7.703e-02  1.000e-01 ...  1.520e-02  1.084e-18]\n",
            "     nit: 4\n",
            "     jac: [ 6.358e-01  5.852e-01 ...  4.773e-01  5.192e-01]\n",
            "    nfev: 65\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.26393939990131304\n",
            "       x: [ 7.672e-02  1.000e-01 ...  1.461e-02  6.939e-18]\n",
            "     nit: 4\n",
            "     jac: [ 6.586e-01  6.056e-01 ...  4.951e-01  5.358e-01]\n",
            "    nfev: 65\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.27619454722275955\n",
            "       x: [ 8.398e-02  1.000e-01 ...  7.098e-04  6.652e-19]\n",
            "     nit: 3\n",
            "     jac: [ 7.024e-01  6.263e-01 ...  5.063e-01  5.582e-01]\n",
            "    nfev: 60\n",
            "    njev: 3\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.2845793731940776\n",
            "       x: [ 7.575e-02  1.000e-01 ...  1.409e-02  0.000e+00]\n",
            "     nit: 4\n",
            "     jac: [ 7.037e-01  6.466e-01 ...  5.315e-01  5.693e-01]\n",
            "    nfev: 65\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.2949342153115295\n",
            "       x: [ 7.308e-02  1.000e-01 ...  1.386e-02  0.000e+00]\n",
            "     nit: 4\n",
            "     jac: [ 7.234e-01  6.665e-01 ...  5.491e-01  5.861e-01]\n",
            "    nfev: 65\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.3052281991994539\n",
            "       x: [ 7.423e-02  1.000e-01 ...  1.331e-02  0.000e+00]\n",
            "     nit: 4\n",
            "     jac: [ 7.481e-01  6.882e-01 ...  5.678e-01  6.030e-01]\n",
            "    nfev: 65\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.3155617150783948\n",
            "       x: [ 7.340e-02  1.000e-01 ...  1.269e-02  5.508e-17]\n",
            "     nit: 4\n",
            "     jac: [ 7.704e-01  7.093e-01 ...  5.859e-01  6.201e-01]\n",
            "    nfev: 65\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.32593384472833753\n",
            "       x: [ 7.210e-02  1.000e-01 ...  1.212e-02  6.505e-18]\n",
            "     nit: 4\n",
            "     jac: [ 7.919e-01  7.312e-01 ...  6.042e-01  6.375e-01]\n",
            "    nfev: 65\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.33632019264444596\n",
            "       x: [ 7.060e-02  1.000e-01 ...  1.140e-02  0.000e+00]\n",
            "     nit: 4\n",
            "     jac: [ 8.129e-01  7.532e-01 ...  6.224e-01  6.551e-01]\n",
            "    nfev: 65\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.3467223747576721\n",
            "       x: [ 6.903e-02  1.000e-01 ...  1.070e-02  0.000e+00]\n",
            "     nit: 4\n",
            "     jac: [ 8.338e-01  7.754e-01 ...  6.407e-01  6.727e-01]\n",
            "    nfev: 65\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.3571437795955163\n",
            "       x: [ 6.741e-02  1.000e-01 ...  9.997e-03  1.475e-17]\n",
            "     nit: 4\n",
            "     jac: [ 8.544e-01  7.977e-01 ...  6.590e-01  6.905e-01]\n",
            "    nfev: 65\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.367588139903152\n",
            "       x: [ 6.573e-02  1.000e-01 ...  9.306e-03  6.158e-17]\n",
            "     nit: 4\n",
            "     jac: [ 8.748e-01  8.203e-01 ...  6.773e-01  7.083e-01]\n",
            "    nfev: 65\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.3775111745491855\n",
            "       x: [ 8.217e-02  1.000e-01 ...  6.775e-03  0.000e+00]\n",
            "     nit: 4\n",
            "     jac: [ 8.950e-01  8.430e-01 ...  6.957e-01  7.263e-01]\n",
            "    nfev: 66\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.38786947136001554\n",
            "       x: [ 8.262e-02  1.000e-01 ...  5.928e-03  2.342e-17]\n",
            "     nit: 4\n",
            "     jac: [ 9.150e-01  8.658e-01 ...  7.142e-01  7.444e-01]\n",
            "    nfev: 66\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.39823004641422777\n",
            "       x: [ 8.314e-02  1.000e-01 ...  5.111e-03  2.862e-17]\n",
            "     nit: 4\n",
            "     jac: [ 9.348e-01  8.889e-01 ...  7.327e-01  7.626e-01]\n",
            "    nfev: 66\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.40859432141650753\n",
            "       x: [ 8.374e-02  1.000e-01 ...  4.329e-03  0.000e+00]\n",
            "     nit: 5\n",
            "     jac: [ 1.005e+00  8.926e-01 ...  7.421e-01  7.733e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.4189641809497046\n",
            "       x: [ 8.444e-02  1.000e-01 ...  3.581e-03  2.602e-17]\n",
            "     nit: 5\n",
            "     jac: [ 1.032e+00  9.132e-01 ...  7.599e-01  7.907e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.4293399238227626\n",
            "       x: [ 8.520e-02  1.000e-01 ...  2.856e-03  2.082e-17]\n",
            "     nit: 5\n",
            "     jac: [ 1.058e+00  9.338e-01 ...  7.777e-01  8.082e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.4397228149696328\n",
            "       x: [ 8.602e-02  1.000e-01 ...  2.150e-03  5.378e-17]\n",
            "     nit: 5\n",
            "     jac: [ 1.085e+00  9.545e-01 ...  7.955e-01  8.257e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.4546903188295585\n",
            "       x: [ 9.284e-02  1.000e-01 ...  3.816e-17  9.714e-17]\n",
            "     nit: 3\n",
            "     jac: [ 1.105e+00  9.390e-01 ...  7.889e-01  8.159e-01]\n",
            "    nfev: 60\n",
            "    njev: 3\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.46048428869858593\n",
            "       x: [ 8.725e-02  1.000e-01 ...  8.674e-04  4.510e-17]\n",
            "     nit: 5\n",
            "     jac: [ 1.138e+00  9.960e-01 ...  8.314e-01  8.609e-01]\n",
            "    nfev: 81\n",
            "    njev: 5\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.4708691522841153\n",
            "       x: [ 8.819e-02  1.000e-01 ...  8.343e-04  3.556e-17]\n",
            "     nit: 4\n",
            "     jac: [ 1.112e+00  1.012e+00 ...  8.407e-01  8.733e-01]\n",
            "    nfev: 67\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.4812477507273916\n",
            "       x: [ 8.823e-02  1.000e-01 ...  0.000e+00  0.000e+00]\n",
            "     nit: 4\n",
            "     jac: [ 1.127e+00  1.041e+00 ...  8.628e-01  8.889e-01]\n",
            "    nfev: 67\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.49124332378209495\n",
            "       x: [ 7.856e-02  1.000e-01 ...  3.865e-04  2.461e-18]\n",
            "     nit: 4\n",
            "     jac: [ 1.150e+00  1.062e+00 ...  8.803e-01  9.057e-01]\n",
            "    nfev: 68\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.5020366669513747\n",
            "       x: [ 8.483e-02  1.000e-01 ...  2.031e-04  3.830e-11]\n",
            "     nit: 4\n",
            "     jac: [ 1.179e+00  1.072e+00 ...  8.928e-01  9.182e-01]\n",
            "    nfev: 67\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.5123444100836135\n",
            "       x: [ 8.861e-02  1.000e-01 ...  2.700e-17  0.000e+00]\n",
            "     nit: 4\n",
            "     jac: [ 1.196e+00  1.099e+00 ...  9.134e-01  9.438e-01]\n",
            "    nfev: 67\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.5222357653191606\n",
            "       x: [ 7.822e-02  1.000e-01 ...  4.739e-17  5.588e-17]\n",
            "     nit: 4\n",
            "     jac: [ 1.220e+00  1.123e+00 ...  9.333e-01  9.564e-01]\n",
            "    nfev: 68\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.5330561842476806\n",
            "       x: [ 8.881e-02  1.000e-01 ...  0.000e+00  2.385e-17]\n",
            "     nit: 4\n",
            "     jac: [ 1.246e+00  1.141e+00 ...  9.511e-01  9.823e-01]\n",
            "    nfev: 67\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.5428964804735806\n",
            "       x: [ 7.803e-02  1.000e-01 ...  7.830e-18  3.396e-17]\n",
            "     nit: 4\n",
            "     jac: [ 1.267e+00  1.165e+00 ...  9.698e-01  9.904e-01]\n",
            "    nfev: 68\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.553226434062024\n",
            "       x: [ 7.795e-02  1.000e-01 ...  1.082e-17  2.935e-17]\n",
            "     nit: 4\n",
            "     jac: [ 1.291e+00  1.186e+00 ...  9.881e-01  1.007e+00]\n",
            "    nfev: 68\n",
            "    njev: 4\n",
            " message: Optimization terminated successfully\n",
            " success: True\n",
            "  status: 0\n",
            "     fun: 0.5635556748043745\n",
            "       x: [ 7.789e-02  1.000e-01 ...  3.574e-17  5.072e-17]\n",
            "     nit: 4\n",
            "     jac: [ 1.314e+00  1.206e+00 ...  1.006e+00  1.024e+00]\n",
            "    nfev: 68\n",
            "    njev: 4\n",
            "Optimal weights of the efficient set portfolios\n",
            ": [[0.1   0.    0.1   0.    0.1   0.    0.    0.248 0.    0.1   0.    0.015\n",
            "  0.    0.337 0.   ]\n",
            " [0.1   0.    0.1   0.    0.1   0.    0.    0.224 0.    0.1   0.    0.101\n",
            "  0.    0.274 0.   ]\n",
            " [0.1   0.    0.1   0.    0.1   0.    0.    0.215 0.    0.1   0.    0.13\n",
            "  0.    0.255 0.   ]\n",
            " [0.1   0.    0.1   0.    0.1   0.    0.    0.204 0.    0.1   0.005 0.155\n",
            "  0.    0.236 0.   ]\n",
            " [0.1   0.006 0.1   0.    0.1   0.    0.    0.18  0.    0.094 0.049 0.168\n",
            "  0.    0.203 0.   ]\n",
            " [0.1   0.018 0.1   0.    0.1   0.    0.    0.158 0.    0.082 0.089 0.18\n",
            "  0.    0.173 0.   ]\n",
            " [0.1   0.03  0.1   0.    0.1   0.    0.    0.138 0.    0.07  0.125 0.19\n",
            "  0.    0.147 0.   ]\n",
            " [0.1   0.041 0.1   0.    0.1   0.    0.    0.119 0.    0.059 0.159 0.199\n",
            "  0.    0.123 0.   ]\n",
            " [0.1   0.049 0.1   0.    0.1   0.    0.    0.103 0.    0.051 0.187 0.204\n",
            "  0.    0.106 0.   ]\n",
            " [0.095 0.06  0.1   0.    0.1   0.    0.    0.089 0.    0.044 0.211 0.208\n",
            "  0.002 0.09  0.   ]\n",
            " [0.088 0.072 0.098 0.    0.1   0.    0.    0.077 0.    0.042 0.23  0.209\n",
            "  0.007 0.077 0.   ]\n",
            " [0.084 0.083 0.09  0.    0.1   0.005 0.    0.067 0.    0.043 0.243 0.207\n",
            "  0.011 0.068 0.   ]\n",
            " [0.082 0.092 0.083 0.    0.1   0.009 0.    0.059 0.    0.043 0.254 0.204\n",
            "  0.014 0.06  0.   ]\n",
            " [0.08  0.099 0.078 0.    0.1   0.013 0.    0.052 0.    0.043 0.263 0.203\n",
            "  0.016 0.053 0.   ]\n",
            " [0.08  0.1   0.075 0.    0.1   0.017 0.    0.046 0.    0.045 0.27  0.2\n",
            "  0.018 0.048 0.   ]\n",
            " [0.08  0.1   0.073 0.    0.1   0.021 0.    0.041 0.    0.047 0.276 0.198\n",
            "  0.02  0.044 0.   ]\n",
            " [0.081 0.1   0.071 0.    0.1   0.023 0.    0.037 0.    0.048 0.282 0.197\n",
            "  0.022 0.04  0.   ]\n",
            " [0.081 0.1   0.069 0.    0.1   0.025 0.    0.032 0.    0.05  0.288 0.195\n",
            "  0.022 0.036 0.   ]\n",
            " [0.081 0.1   0.067 0.    0.1   0.026 0.    0.027 0.    0.052 0.297 0.194\n",
            "  0.022 0.033 0.   ]\n",
            " [0.08  0.1   0.065 0.    0.1   0.028 0.    0.022 0.    0.055 0.304 0.192\n",
            "  0.022 0.031 0.   ]\n",
            " [0.08  0.1   0.063 0.    0.099 0.029 0.    0.019 0.    0.058 0.31  0.191\n",
            "  0.023 0.029 0.   ]\n",
            " [0.079 0.1   0.062 0.    0.098 0.03  0.    0.015 0.    0.061 0.315 0.189\n",
            "  0.023 0.027 0.   ]\n",
            " [0.079 0.1   0.061 0.    0.097 0.032 0.    0.012 0.    0.063 0.32  0.187\n",
            "  0.023 0.026 0.   ]\n",
            " [0.079 0.1   0.059 0.    0.096 0.033 0.    0.01  0.    0.065 0.324 0.185\n",
            "  0.023 0.025 0.   ]\n",
            " [0.079 0.1   0.058 0.    0.095 0.034 0.    0.007 0.    0.067 0.328 0.183\n",
            "  0.024 0.024 0.   ]\n",
            " [0.082 0.1   0.067 0.    0.1   0.046 0.    0.045 0.    0.051 0.239 0.187\n",
            "  0.055 0.028 0.   ]\n",
            " [0.079 0.1   0.056 0.    0.094 0.036 0.    0.003 0.    0.071 0.335 0.179\n",
            "  0.024 0.022 0.   ]\n",
            " [0.079 0.1   0.055 0.    0.094 0.037 0.    0.002 0.    0.072 0.338 0.177\n",
            "  0.024 0.021 0.   ]\n",
            " [0.08  0.1   0.054 0.    0.093 0.038 0.    0.001 0.    0.073 0.341 0.176\n",
            "  0.024 0.02  0.   ]\n",
            " [0.077 0.1   0.059 0.    0.096 0.04  0.    0.011 0.    0.068 0.31  0.188\n",
            "  0.036 0.015 0.   ]\n",
            " [0.077 0.1   0.058 0.    0.096 0.041 0.    0.008 0.    0.07  0.314 0.187\n",
            "  0.036 0.015 0.   ]\n",
            " [0.084 0.1   0.062 0.    0.1   0.041 0.    0.023 0.    0.054 0.282 0.203\n",
            "  0.051 0.001 0.   ]\n",
            " [0.076 0.1   0.057 0.    0.095 0.041 0.    0.003 0.    0.073 0.323 0.184\n",
            "  0.034 0.014 0.   ]\n",
            " [0.073 0.1   0.054 0.    0.1   0.042 0.    0.001 0.    0.073 0.326 0.183\n",
            "  0.034 0.014 0.   ]\n",
            " [0.074 0.1   0.055 0.    0.094 0.043 0.    0.    0.    0.077 0.33  0.181\n",
            "  0.033 0.013 0.   ]\n",
            " [0.073 0.1   0.055 0.    0.094 0.043 0.    0.    0.    0.078 0.333 0.18\n",
            "  0.032 0.013 0.   ]\n",
            " [0.072 0.1   0.054 0.    0.093 0.044 0.002 0.    0.    0.08  0.335 0.178\n",
            "  0.031 0.012 0.   ]\n",
            " [0.071 0.1   0.053 0.    0.092 0.044 0.003 0.    0.    0.081 0.338 0.175\n",
            "  0.031 0.011 0.   ]\n",
            " [0.069 0.1   0.052 0.    0.092 0.045 0.005 0.    0.    0.082 0.34  0.173\n",
            "  0.031 0.011 0.   ]\n",
            " [0.067 0.1   0.051 0.    0.091 0.046 0.007 0.    0.    0.084 0.342 0.171\n",
            "  0.032 0.01  0.   ]\n",
            " [0.066 0.1   0.05  0.    0.09  0.047 0.009 0.    0.    0.085 0.344 0.168\n",
            "  0.032 0.009 0.   ]\n",
            " [0.082 0.1   0.048 0.    0.091 0.047 0.    0.    0.    0.078 0.356 0.162\n",
            "  0.029 0.007 0.   ]\n",
            " [0.083 0.1   0.048 0.    0.091 0.048 0.    0.    0.    0.078 0.356 0.161\n",
            "  0.029 0.006 0.   ]\n",
            " [0.083 0.1   0.048 0.    0.091 0.048 0.    0.    0.    0.078 0.357 0.16\n",
            "  0.03  0.005 0.   ]\n",
            " [0.084 0.1   0.048 0.    0.091 0.049 0.    0.    0.    0.077 0.358 0.159\n",
            "  0.03  0.004 0.   ]\n",
            " [0.084 0.1   0.047 0.    0.091 0.05  0.    0.    0.    0.077 0.358 0.158\n",
            "  0.031 0.004 0.   ]\n",
            " [0.085 0.1   0.047 0.    0.091 0.051 0.    0.    0.    0.076 0.359 0.157\n",
            "  0.031 0.003 0.   ]\n",
            " [0.086 0.1   0.047 0.    0.091 0.051 0.    0.    0.    0.076 0.359 0.155\n",
            "  0.032 0.002 0.   ]\n",
            " [0.093 0.1   0.049 0.    0.1   0.    0.    0.    0.    0.058 0.372 0.22\n",
            "  0.008 0.    0.   ]\n",
            " [0.087 0.1   0.046 0.    0.091 0.053 0.    0.    0.    0.075 0.36  0.153\n",
            "  0.033 0.001 0.   ]\n",
            " [0.088 0.1   0.049 0.    0.087 0.053 0.    0.    0.    0.076 0.36  0.152\n",
            "  0.034 0.001 0.   ]\n",
            " [0.088 0.1   0.046 0.    0.091 0.054 0.    0.    0.    0.075 0.36  0.151\n",
            "  0.035 0.    0.   ]\n",
            " [0.079 0.1   0.045 0.001 0.091 0.044 0.007 0.    0.    0.077 0.364 0.161\n",
            "  0.03  0.    0.   ]\n",
            " [0.085 0.1   0.044 0.    0.1   0.054 0.    0.    0.    0.071 0.36  0.151\n",
            "  0.034 0.    0.   ]\n",
            " [0.089 0.1   0.049 0.    0.086 0.056 0.    0.    0.    0.077 0.36  0.149\n",
            "  0.036 0.    0.   ]\n",
            " [0.078 0.1   0.045 0.002 0.091 0.044 0.008 0.    0.    0.077 0.366 0.16\n",
            "  0.03  0.    0.   ]\n",
            " [0.089 0.1   0.047 0.    0.088 0.056 0.    0.    0.    0.077 0.36  0.148\n",
            "  0.036 0.    0.   ]\n",
            " [0.078 0.1   0.044 0.002 0.091 0.044 0.009 0.    0.    0.076 0.367 0.159\n",
            "  0.03  0.    0.   ]\n",
            " [0.078 0.1   0.044 0.002 0.091 0.044 0.009 0.    0.    0.076 0.368 0.158\n",
            "  0.03  0.    0.   ]\n",
            " [0.078 0.1   0.044 0.003 0.091 0.044 0.009 0.    0.    0.076 0.368 0.158\n",
            "  0.03  0.    0.   ]]\n",
            "\n",
            "Annualized Risk and Return of the efficient set portfolios:\n",
            " [[15.375 21.883]\n",
            " [14.708 21.105]\n",
            " [14.523 20.848]\n",
            " [14.331 20.536]\n",
            " [13.864 19.582]\n",
            " [13.468 18.669]\n",
            " [13.149 17.833]\n",
            " [12.895 17.072]\n",
            " [12.717 16.458]\n",
            " [12.561 15.833]\n",
            " [12.438 15.265]\n",
            " [12.337 14.743]\n",
            " [12.263 14.319]\n",
            " [12.207 13.963]\n",
            " [12.176 13.749]\n",
            " [12.152 13.574]\n",
            " [12.132 13.415]\n",
            " [12.112 13.252]\n",
            " [12.092 13.073]\n",
            " [12.077 12.921]\n",
            " [12.064 12.788]\n",
            " [12.054 12.672]\n",
            " [12.046 12.569]\n",
            " [12.039 12.475]\n",
            " [12.033 12.39 ]\n",
            " [12.178 13.458]\n",
            " [12.024 12.242]\n",
            " [12.02  12.178]\n",
            " [12.017 12.119]\n",
            " [12.04  12.406]\n",
            " [12.034 12.328]\n",
            " [12.083 12.635]\n",
            " [12.025 12.187]\n",
            " [12.021 12.118]\n",
            " [12.018 12.067]\n",
            " [12.015 12.022]\n",
            " [12.013 11.958]\n",
            " [12.012 11.891]\n",
            " [12.011 11.824]\n",
            " [12.01  11.757]\n",
            " [12.01  11.691]\n",
            " [12.004 11.737]\n",
            " [12.004 11.719]\n",
            " [12.004 11.702]\n",
            " [12.004 11.686]\n",
            " [12.004 11.67 ]\n",
            " [12.005 11.655]\n",
            " [12.005 11.641]\n",
            " [12.069 11.959]\n",
            " [12.006 11.613]\n",
            " [12.006 11.611]\n",
            " [12.006 11.591]\n",
            " [12.002 11.489]\n",
            " [12.008 11.592]\n",
            " [12.007 11.581]\n",
            " [12.002 11.446]\n",
            " [12.008 11.572]\n",
            " [12.002 11.422]\n",
            " [12.002 11.411]\n",
            " [12.002 11.4  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "NoPoints = riskPoint.size\n",
        "\n",
        "colours = \"blue\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for constrained k-portfolio 1 of Dow stocks')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(riskPoint, retPoint, s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "FnQRPGeCEJ8c",
        "outputId": "ec6db54a-7d53-4147-96e0-0e91944a7753"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}